{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "llm = ChatOpenAI( model_name=\"custom\",\n",
    "openai_api_key='3c52000cbd5f8bd87edfca29d9f8a102', \n",
    "openai_api_base='http://localhost:5000/v1',\n",
    "# model_kwargs={\n",
    "#     \"logit_bias\":{\n",
    "#         # \"320\":-100,\n",
    "#         # \"2474\":-100,\n",
    "#         \"20122\":-100\n",
    "#     }    \n",
    "# },\n",
    "temperature=0,\n",
    "streaming=True,\n",
    "verbose=True )\n",
    "\n",
    "\n",
    "set_debug(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import Ollama\n",
    "from langchain.globals import set_debug\n",
    "llm = Ollama(model=\"custom\")\n",
    "set_debug(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(first_int: int, second_int: int) -> int:\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    return first_int * second_int\n",
    "@tool\n",
    "def add(first_int: int, second_int: int) -> int:\n",
    "    \"Add two integers.\"\n",
    "    return first_int + second_int\n",
    "\n",
    "\n",
    "@tool\n",
    "def exponentiate(base: int, exponent: int) -> int:\n",
    "    \"Exponentiate the base to the exponent power.\"\n",
    "    return base**exponent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.render import render_text_description\n",
    "\n",
    "tools = [multiply, exponentiate, add]\n",
    "tool_map = {tool.name: tool for tool in tools}\n",
    "rendered_tools = render_text_description(tools)\n",
    "rendered_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "System:You are an assistant that has access to the following set of tools. Here are the names and descriptions for each tool:\n",
    "\n",
    "{rendered_tools}\n",
    "\n",
    "Given the user input, return the name and input of the tool to use. Return your response as a JSON blob with 'name' and 'arguments' keys.\n",
    "Arguments is an dictionary of the arguments to pass to the tool.\n",
    "Return only the JSON. Do not include any other text in your response.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_prompt), (\"user\", \"Question:{input} \\n Response:\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chain = prompt | llm | JsonOutputParser()\n",
    "chain.invoke({\"input\": \"what's thirteen times 4\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from langchain_core.runnables import Runnable,RunnableLambda,RunnablePassthrough\n",
    "def call_tool(args: dict) -> Union[str, Runnable]:\n",
    "    \"\"\"Function for dynamically constructing the end of the chain based on the model-selected tool.\"\"\"\n",
    "\n",
    "    tool = tool_map[args[\"name\"]]\n",
    "    return RunnablePassthrough.assign(output=itemgetter(\"arguments\") | tool)\n",
    "call_tool_list = RunnableLambda(call_tool).map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = prompt | llm | JsonOutputParser() | call_tool\n",
    "chain.invoke({\"input\": \"what's thirteen + one million\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_webui",
   "language": "python",
   "name": "text_webui"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
