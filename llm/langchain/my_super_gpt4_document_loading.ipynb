{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install GitPython sentence-transformers tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv /notebooks/chainlang/my.env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xxx DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database =\"KNOWLEDGE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "import openai\n",
    "import gradio as gr\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.text_splitter import Language\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings,GPT4AllEmbeddings,OpenAIEmbeddings\n",
    "from langchain.vectorstores.utils import filter_complex_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db  = Chroma(persist_directory=database, embedding_function=embedding )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD LANGCHAIN REPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "try:\n",
    "    repo = Repo.clone_from(\n",
    "        \"https://github.com/langchain-ai/langchain\", to_path=\"/notebooks/langchain_git\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    pass  # This will catch any exception and do nothing about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitLoader\n",
    "loader = GitLoader(repo_path=\"/notebooks/langchain_git\", branch=\"master\",  file_filter=lambda file_path: file_path.endswith(\".md\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN, chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "docs = splitter.split_documents(data)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitLoader\n",
    "loader = GitLoader(repo_path=\"/notebooks/langchain_git\", branch=\"master\",  file_filter=lambda file_path: file_path.endswith(\".py\"))\n",
    "data = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "docs = splitter.split_documents(data)\n",
    "len(docs)\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD xxx DOCUMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = \"xxx2\"\n",
    "embedding = OpenAIEmbeddings()\n",
    "db  = Chroma(persist_directory=database, embedding_function=embedding )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "try:\n",
    "    repo = Repo.clone_from(\n",
    "        \"https://github.com/laravel/docs\", to_path=\"/notebooks/laraveldocs\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    repo = \"/notebooks/laraveldocs\"\n",
    "    pass  # This will catch any exception and do nothing about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitLoader\n",
    "\n",
    "\n",
    "loader = GitLoader(repo_path=\"/notebooks/laraveldocs\", branch=\"10.x\",  file_filter=lambda file_path: file_path.endswith(\".md\"))\n",
    "data = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN, chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "docs = splitter.split_documents(data)\n",
    "len(docs)\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "try:\n",
    "    repo = Repo.clone_from(\n",
    "        \"https://github.com/laravel/docs\", to_path=\"/notebooks/laraveldocs9\"\n",
    "    )\n",
    "except Exception as e:\n",
    "\n",
    "    pass  # This will catch any exception and do nothing about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitLoader\n",
    "\n",
    "\n",
    "loader = GitLoader(repo_path=\"/notebooks/laraveldocs9\", branch=\"9.x\",  file_filter=lambda file_path: file_path.endswith(\".md\"))\n",
    "data = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN, chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "docs = splitter.split_documents(data)\n",
    "len(docs)\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "try:\n",
    "    repo = Repo.clone_from(\n",
    "        \"https://github.com/nuwave/lighthouse\", to_path=\"/notebooks/lighthouse\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    pass  # This will catch any exception and do nothing about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitLoader\n",
    "\n",
    "\n",
    "loader = GitLoader(repo_path=\"/notebooks/lighthouse\", branch=\"master\",  file_filter=lambda file_path: file_path.endswith(\".md\") and \"docs/\" in file_path   )\n",
    "data = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN, chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "docs = splitter.split_documents(data)\n",
    "print(len(docs))\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv /notebooks/chainlang/my.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from git import Repo\n",
    "\n",
    "# Get the GitHub token from the environment variable\n",
    "github_token = os.environ['GITHUB_TOKEN']\n",
    "\n",
    "# Construct the URL for cloning\n",
    "url = f\"https://{github_token}:x-oauth-basic@github.com/pacificproweb/lcd-toyota-loc.git\"\n",
    "\n",
    "# Clone the repository\n",
    "repo = Repo.clone_from(\n",
    "    url, to_path=\"/notebooks/locations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitLoader\n",
    "\n",
    "branch = repo.head.reference\n",
    "loader = GitLoader(repo_path=\"/notebooks/locations\", branch=\"main\",  file_filter=lambda file_path: file_path.endswith(\".php\") and \"app\" in file_path  )\n",
    "data = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PHP, chunk_size=4000, chunk_overlap=0\n",
    ")\n",
    "docs = splitter.split_documents(data)\n",
    "print(len(docs))\n",
    "\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitLoader\n",
    "\n",
    "branch = repo.head.reference\n",
    "loader = GitLoader(repo_path=\"/notebooks/locations\", branch=\"main\",  file_filter=lambda file_path: file_path.endswith(\".graphql\")  )\n",
    "data = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "   chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "docs = splitter.split_documents(data)\n",
    "print(len(docs))\n",
    "\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitLoader\n",
    "\n",
    "branch = repo.head.reference\n",
    "loader = GitLoader(repo_path=\"/notebooks/locations\", branch=\"main\",  file_filter=lambda file_path: file_path.endswith((\".js\", \".tsx\", \".jsx\", \".ts\"))  and \"resources/js\" in file_path)\n",
    "data = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.JS, chunk_size=4000, chunk_overlap=0\n",
    ")\n",
    "docs = splitter.split_documents(data)\n",
    "print(len(docs))\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /notebooks/locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "try:\n",
    "    repo = Repo.clone_from(\n",
    "        \"https://github.com/apollographql/apollo-client\", to_path=\"/notebooks/apollo-cleint\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    pass  # This will catch any exception and do nothing about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitLoader\n",
    "\n",
    "loader = GitLoader(repo_path=\"/notebooks/apollo-cleint\", branch=\"master\",  file_filter=lambda file_path: file_path.endswith(\".mdx\") and \"docs/\" in file_path   )\n",
    "data = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN, chunk_size=2500, chunk_overlap=0\n",
    ")\n",
    "docs = splitter.split_documents(data)\n",
    "print(len(docs))\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from git import Repo\n",
    "\n",
    "# Get the GitHub token from the environment variable\n",
    "github_token = os.environ['GITHUB_TOKEN']\n",
    "# Construct the URL for cloning\n",
    "url = f\"https://{github_token}:x-oauth-basic@github.com/pacificproweb/vroom.git\"\n",
    "\n",
    "# Clone the repository\n",
    "repo = Repo.clone_from(\n",
    "    url, to_path=\"/notebooks/vroom\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitLoader\n",
    "\n",
    "branch = repo.head.reference\n",
    "loader = GitLoader(repo_path=\"/notebooks/vroom\", branch=\"main\",  file_filter=lambda file_path: file_path.endswith((\".js\", \".tsx\", \".jsx\", \".ts\"))  and \"resources/js\" in file_path)\n",
    "data=loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.JS, chunk_size=2500, chunk_overlap=0\n",
    ")\n",
    "docs = splitter.split_documents(data)\n",
    "print(len(docs))\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitLoader\n",
    "\n",
    "branch = repo.head.reference\n",
    "loader = GitLoader(repo_path=\"/notebooks/vroom\", branch=\"main\",  file_filter=lambda file_path: file_path.endswith(\".php\") and \"app\" in file_path  )\n",
    "data = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PHP, chunk_size=2500, chunk_overlap=0\n",
    ")\n",
    "docs = splitter.split_documents(data)\n",
    "print(len(docs))\n",
    "\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf vroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from git import Repo\n",
    "\n",
    "# Get the GitHub token from the environment variable\n",
    "github_token = os.environ['GITHUB_TOKEN']\n",
    "# Construct the URL for cloning\n",
    "url = f\"https://{github_token}:x-oauth-basic@github.com/pacificproweb/rest-nav-360.git\"\n",
    "\n",
    "# Clone the repository\n",
    "repo = Repo.clone_from(\n",
    "    url, to_path=\"/notebooks/rest-nav-360\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitLoader\n",
    "\n",
    "branch = repo.head.reference\n",
    "loader = GitLoader(repo_path=\"/notebooks/rest-nav-360\", branch=\"main\",  file_filter=lambda file_path: file_path.endswith(\".graphql\")  )\n",
    "data = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "   chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "docs = splitter.split_documents(data)\n",
    "print(len(docs))\n",
    "\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitLoader\n",
    "\n",
    "branch = repo.head.reference\n",
    "loader = GitLoader(repo_path=\"/notebooks/rest-nav-360\", branch=\"main\",  file_filter=lambda file_path: file_path.endswith(\".php\") and \"app\" in file_path  )\n",
    "data = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PHP, chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "docs = splitter.split_documents(data)\n",
    "print(len(docs))\n",
    "\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitLoader\n",
    "\n",
    "branch = repo.head.reference\n",
    "loader = GitLoader(repo_path=\"/notebooks/rest-nav-360\", branch=\"main\",  file_filter=lambda file_path: file_path.endswith((\".js\", \".tsx\", \".jsx\", \".ts\"))  and \"resources/js\" in file_path)\n",
    "data=loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.JS, chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "docs = splitter.split_documents(data)\n",
    "print(len(docs))\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf rest-nav-360 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r {database}.zip /notebooks/{database}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
