{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace=\"notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /$workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/oobabooga/text-generation-webui.git text-generation-webui-repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /$workspace/text-generation-webui-repo\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /$workspace/text-generation-webui-repo/extensions\n",
    "!git clone https://github.com/Brawlence/SD_api_pics\n",
    "%cd /$workspace/text-generation-webui-repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch  torchvision torchaudio xformers   --index-url https://download.pytorch.org/whl/nightly/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install xformers --index-url https://download.pytorch.org/whl/nightly/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%env FORCE_CMAKE=1\n",
    "%env CMAKE_ARGS=-DLLAMA_CUBLAS=on\n",
    "os.environ['CMAKE_ARGS'] = \"-DLLAMA_CUBLAS=on\"\n",
    "os.environ['FORCE_CMAKE'] = \"1\"\n",
    "#%env FORCE_CMAKE=1\n",
    "#%env CMAKE_ARGS=-DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS\n",
    "#os.environ['CMAKE_ARGS'] = \"-DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS\"\n",
    "#os.environ['FORCE_CMAKE'] = \"1\"\n",
    "%pip install  --upgrade --force-reinstall  git+https://github.com/abetlen/llama-cpp-python --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%cd /$workspace\n",
    "os.environ['CUDA_VERSION'] = \"121\"\n",
    "%pip uninstall bitsandbytes -y\n",
    "!git clone https://github.com/TimDettmers/bitsandbytes.git\n",
    "%cd /$workspace/bitsandbytes\n",
    "!git pull origin main\n",
    "%env CUDA_VERSION=121\n",
    "!make cuda11x\n",
    "%run setup.py install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /$workspace/\n",
    "!git clone https://github.com/huggingface/transformers.git\n",
    "%cd transformers\n",
    "!git pull\n",
    "%pip install -e .\n",
    "%cd /$workspace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install SpeechRecognition==3.10.0\n",
    "%pip install flask_cloudflared==0.0.14\n",
    "%pip install sse-starlette==1.6.5\n",
    "%pip install tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%cd /notebooks\n",
    "!rm /notebooks/llama-cpp-python\n",
    "!git clone --recurse-submodules https://github.com/abetlen/llama-cpp-python.git\n",
    "%cd /notebooks/llama-cpp-python\n",
    "!git pull\n",
    "#%cd /notebooks/llama-cpp-python/vendor\n",
    "#!git clone https://github.com/ggerganov/llama.cpp.git\n",
    "%cd /notebooks/llama-cpp-python/vendor/llama.cpp\n",
    "#!git checkout mixtral\n",
    "!git pull\n",
    "#!rm build -rf\n",
    "#!mkdir build\n",
    "#%cd build\n",
    "#!cmake .. -DLLAMA_CUBLAS=ON   #-DLLAMA_CUBLAS=ON  DLLAMA_CUDA_FORCE_MMQ=ON\n",
    "#!cmake --build . --config Release\n",
    "%cd /notebooks/llama-cpp-python\n",
    "os.environ['CMAKE_ARGS'] = \"-DLLAMA_CUBLAS=on\"\n",
    "os.environ['FORCE_CMAKE'] = \"1\"\n",
    "%env  -DLLAMA_CUBLAS=ON #CMAKE_ARGS=\"-DLLAMA_CUBLAS=ON -DLLAMA_CUDA_FORCE_MMQ=ON\"\n",
    "%pip uninstall -y llama_cpp_python llama_cpp_python_cuda\n",
    "%pip install -v -e  .[server] --upgrade  --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /notebooks/\n",
    "!git clone https://github.com/huggingface/transformers.git\n",
    "%cd transformers\n",
    "!git pull\n",
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd /notebooks/text-generation-webui-repo/extensions/openai/\n",
    "#%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install gekko\n",
    "#%pip install  optimum\n",
    "#%pip install gekko\n",
    "#%pip  install git+https://github.com/PanQiWei/AutoGPTQ.git --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu112/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run llm/text_generation_webui.ipynb.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workspace=\"notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd /$workspace/text-generation-webui-repo  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #--multi-user  #--model Emerhyst-20B-GPTQ\n",
    "#%run server.py --chat-buttons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_webui",
   "language": "python",
   "name": "text_webui"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
