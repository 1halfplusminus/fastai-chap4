{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TABULOR MODEL FRON SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch numpy pandas fastai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./Titanic/train.csv')\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modes = df.mode().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(modes, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df.describe(include=(np.number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fare'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LogFare'] = np.log1p(df['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LogFare'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclasses = sorted(df.Pclass.unique())\n",
    "pclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df,columns=[\"Sex\",\"Pclass\",\"Embarked\"])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "\n",
    "t_dep = tensor(df.Survived)\n",
    "added_cols= ['Sex_male','Sex_female','Pclass_1','Pclass_2','Pclass_3','Embarked_C','Embarked_Q','Embarked_S']\n",
    "indep_cols = ['Age','SibSp','Parch','LogFare'] + added_cols\n",
    "t_indep = tensor(df[indep_cols].values, dtype=torch.float32)\n",
    "t_indep.shape\n",
    "df[indep_cols].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(442)\n",
    "\n",
    "n_coeff = t_indep.shape[1]\n",
    "coeffs = torch.randn(n_coeff) - 0.5\n",
    "coeffs * t_indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divise by max to normalize value\n",
    "vals,indices = t_indep.max(dim=0)\n",
    "t_indep = t_indep / vals\n",
    "t_indep * coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (t_indep * coeffs).sum(axis=1)\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.abs(preds - t_dep).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs,indeps): return (indeps * coeffs).sum(axis=1)\n",
    "def calc_loss(coeffs,indeps,dep): return torch.abs(calc_preds(coeffs,indeps) - dep).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = calc_loss(coeffs,t_indep,t_dep)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    coeffs.sub_(coeffs.grad * 0.1)\n",
    "    print(calc_loss(coeffs,t_indep,t_dep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import RandomSplitter\n",
    "trn_split,val_split=RandomSplitter(seed=42)(df)\n",
    "\n",
    "trn_indep,val_indep = t_indep[trn_split],t_indep[val_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_indep,val_indep = t_indep[trn_split],t_indep[val_split]\n",
    "trn_dep,val_dep = t_dep[trn_split],t_dep[val_split]\n",
    "len(trn_indep),len(val_indep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs,lr): coeffs.data.sub_(coeffs.grad * lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch(coeffs,lr):\n",
    "    preds = calc_preds(coeffs,trn_indep)\n",
    "    loss = torch.abs(preds - trn_dep).mean()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        update_coeffs(coeffs,lr)\n",
    "    print(f\"{loss:.4f}\",end='; ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(): return (torch.randn(n_coeff) - 0.5).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=30,lr=0.01):\n",
    "\n",
    "    coeffs = init_coeffs()\n",
    "    for i in range(epochs):\n",
    "        one_epoch(coeffs,lr)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = train_model(100,lr=0.02)\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shows_coeffs(): return dict(zip(indep_cols,coeffs.requires_grad_(False)))\n",
    "\n",
    "shows_coeffs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = calc_preds(coeffs,val_indep)\n",
    "results = val_dep.bool() == (preds > 0.5)\n",
    "results[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(coeffs): return (val_dep.bool() == (calc_preds(coeffs,val_indep) > 0.5)).float().mean()\n",
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs,indeps): return torch.sigmoid((indeps * coeffs).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = train_model(150,lr=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df = pd.read_csv('./Titanic/test.csv')\n",
    "tst_df['Fare'] = tst_df.Fare.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df.fillna(modes, inplace=True)\n",
    "tst_df['LogFare'] = np.log1p(tst_df['Fare'])\n",
    "tst_df = pd.get_dummies(tst_df,columns=[\"Sex\",\"Pclass\",\"Embarked\"])\n",
    "\n",
    "tst_indep = tensor(tst_df[indep_cols].values, dtype=torch.float)\n",
    "tst_indep = tst_indep / vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df['Survived'] = (calc_preds(coeffs,tst_indep) > 0.5).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = tst_df[['PassengerId','Survived']]\n",
    "sub_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_preds(coeffs,indeps): return torch.sigmoid(indeps@coeffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(): return (torch.rand(n_coeff,1) * 0.1).requires_grad_()\n",
    "\n",
    "trn_dep = trn_dep[:,None]\n",
    "val_dep = val_dep[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = train_model(1000,lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(n_hidden=20):\n",
    "    layer1 = (torch.rand(n_coeff,n_hidden) - 0.5) / n_hidden\n",
    "    layer2 = torch.rand(n_hidden,1)-0.3\n",
    "    const = torch.rand(1)[0]\n",
    "    return layer1.requires_grad_(),layer2.requires_grad_(),const.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calc_preds(coeffs,indeps):\n",
    "    l1,l2,const = coeffs\n",
    "    res = F.relu(indeps@l1)\n",
    "    res = res@l2 + const\n",
    "    return torch.sigmoid(res)\n",
    "\n",
    "def update_coeffs(coeffs,lr):\n",
    "    for layer in coeffs:\n",
    "        layer.sub_(layer.grad * lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = train_model(lr=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs():\n",
    "    hiddens= [10,10]\n",
    "    sizes = [n_coeff] + hiddens + [1]\n",
    "    n = len(sizes)\n",
    "    layers = [(torch.rand(sizes[i],sizes[i+1])-0.3) / sizes[i+1]*4 for i in range(n-1)]\n",
    "    consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(n-1)]\n",
    "    for l in layers+consts: l.requires_grad_()\n",
    "    return layers,consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs,indeps):\n",
    "    layers,consts = coeffs\n",
    "    n = len(layers)\n",
    "    res = indeps\n",
    "    for i,l in enumerate(layers):\n",
    "        res = res@l + consts[i]\n",
    "        if i!=n-1: res = F.relu(res)\n",
    "    return torch.sigmoid(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs,lr):\n",
    "    layers,conts = coeffs\n",
    "    for layer in layers+conts: layer.sub_(layer.grad * lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = train_model(lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FRAMEWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Titanic/train.csv')\n",
    "\n",
    "def add_features(df):\n",
    "    df['LogFare'] = np.log1p(df['Fare'])\n",
    "    df['Deck'] = df.Cabin.str[0].map(dict(A=\"ABC\",B=\"ABC\",C=\"ABC\",D=\"DE\",E=\"DE\",F=\"FG\",G=\"FG\"))\n",
    "\n",
    "add_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter(seed=42)(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "\n",
    "dls = TabularPandas(df, splits=splits,\n",
    "procs=[Categorify,FillMissing,Normalize]\n",
    ",cat_names=[\"Sex\",\"Pclass\",\"Embarked\",\"Deck\"]\n",
    ",cont_names=[\"Age\",\"SibSp\",\"Parch\",\"LogFare\"]\n",
    ",y_names=\"Survived\",y_block=CategoryBlock()\n",
    ").dataloaders(path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls,metrics=accuracy,layers=[10,10])\n",
    "\n",
    "learn.lr_find(suggest_funcs=(slide,valley))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(16,lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df = pd.read_csv('./Titanic/test.csv')\n",
    "tst_df[\"Fare\"] = tst_df.Fare.fillna(0)\n",
    "add_features(tst_df)\n",
    "\n",
    "tst_dl = learn.dls.test_dl(tst_df)\n",
    "\n",
    "preds,_ = learn.get_preds(dl=tst_dl)\n",
    "print(preds)\n",
    "tst_df['Survived'] = (preds[:,0]>0.5).int()\n",
    "sub_df = tst_df[['PassengerId','Survived']]\n",
    "sub_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# create two tensors\n",
    "a = torch.tensor([[1, 2,3], [3, 4,3]])\n",
    "b = torch.tensor([[5, 6,3], [7, 8,3]])\n",
    "\n",
    "# perform matrix multiplication\n",
    "c = torch.matmul(a, b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# load data\n",
    "data = pd.read_csv('./Titanic/train.csv')\n",
    "data.isna().sum()\n",
    "modes = df.mode().iloc[0]\n",
    "data.fillna(modes, inplace=True)\n",
    "data['Fare'] = np.log(data['Fare'] + 1)  # take the log of the Fare column\n",
    "X = data.drop(['Survived', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1).values\n",
    "y = data['Survived'].values\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "# define model architecture\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(TabularModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# create model\n",
    "model = TabularModel(input_size=X_train.shape[1], hidden_size=64, output_size=1)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train model\n",
    "for epoch in range(100):\n",
    "    # convert data to PyTorch tensors\n",
    "    inputs = torch.tensor(X_train.astype(np.float32))\n",
    "    labels = torch.tensor(y_train.astype(np.float32))\n",
    "    \n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs.squeeze(), labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 100, loss.item()))\n",
    "\n",
    "# evaluate model\n",
    "with torch.no_grad():\n",
    "    # convert data to PyTorch tensors\n",
    "    inputs = torch.tensor(X_test.astype(np.float32))\n",
    "    labels = torch.tensor(y_test.astype(np.float32))\n",
    "    \n",
    "    # make predictions\n",
    "    outputs = model(inputs)\n",
    "    predicted = (outputs > 0).squeeze().long()\n",
    "    \n",
    "    # calculate accuracy\n",
    "    total = labels.size(0)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    print('Accuracy: {:.2f}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST / BINARY SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Titanic/train.csv')\n",
    "tst_df = pd.read_csv('./Titanic/test.csv')\n",
    "modes = df.mode().iloc[0]\n",
    "\n",
    "def proc_data(df):\n",
    "    df['Fare'] = df.Fare.fillna(0)\n",
    "    df.fillna(modes, inplace=True)\n",
    "    df['LogFare'] = np.log1p(df['Fare'])\n",
    "    df['Embarked'] = pd.Categorical(df.Embarked)\n",
    "    df['Sex'] = pd.Categorical(df.Sex)\n",
    "    \n",
    "\n",
    "proc_data(df)\n",
    "proc_data(tst_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=['Sex','Embarked']\n",
    "conts=['Age','SibSp','Parch','LogFare','Pclass']\n",
    "dep=\"Survived\"\n",
    "\n",
    "df.Sex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sex.cat.codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(11,5))\n",
    "sns.barplot(data=df,y=dep,x=\"Sex\",ax=axs[0]).set(title=\"Survival Rate\")\n",
    "sns.countplot(data=df,x=\"Sex\",ax=axs[1]).set(title=\"Histogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42)\n",
    "trn_df,val_df = train_test_split(df,test_size=0.2)\n",
    "trn_df[cats] = trn_df[cats].apply(lambda x: x.cat.codes)\n",
    "val_df[cats] = val_df[cats].apply(lambda x: x.cat.codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xs_y(df):\n",
    "    xs = df[cats+conts].copy()\n",
    "    return xs,df[dep] if dep in df else None\n",
    "\n",
    "trn_xs,trn_y = xs_y(trn_df)\n",
    "val_xs,val_y = xs_y(val_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = val_xs.Sex == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(val_y,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fare = trn_df[trn_df.LogFare > 0]\n",
    "fig,axs= plt.subplots(1,2,figsize=(11,5))\n",
    "sns.boxenplot(data=df_fare,x=dep,y=\"LogFare\",ax=axs[0])\n",
    "sns.kdeplot(data=df_fare,x=\"LogFare\",hue=dep,ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = val_xs.LogFare > 2.7\n",
    "mean_absolute_error(val_y,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _side_score(side,y):\n",
    "    tot= side.sum()\n",
    "    if tot <= 1: return 0\n",
    "    return y[side].std() * tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(col,y,split):\n",
    "    lhs = col <= split\n",
    "    return (_side_score(lhs,y) + _side_score(~lhs,y)) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(trn_xs[\"Sex\"],trn_y,0.5)\n",
    "score(trn_xs[\"Sex\"],trn_y,2.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iscore(nm,split):\n",
    "    col = trn_xs[nm]\n",
    "    return score(col,trn_y,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "interact(nm=conts,split=15.5)(iscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(nm=cats,split=2)(iscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm = \"Age\"\n",
    "col = trn_xs[nm]\n",
    "unq = col.unique()\n",
    "unq.sort()\n",
    "unq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array([score(col,trn_y,o) for o in unq if not np.isnan(o)])\n",
    "unq[scores.argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_col(df,nm):\n",
    "    col,y=df[nm],df[dep]\n",
    "    unq= col.dropna().unique()\n",
    "    scores = np.array([score(col,y,o) for o in unq if not np.isnan(o)])\n",
    "    idx = scores.argmin()\n",
    "    return unq[idx],scores[idx]\n",
    "\n",
    "min_col(trn_df,\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = cats + conts\n",
    "{o: min_col(trn_df,o) for o in cols}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
