{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U insightface onnxruntime-gpu  numpy fastai pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U gdown moviepy ffmpeg insightface natsort hdbscan imutils chinese-whispers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import cv2\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip,AudioFileClip\n",
    "import glob\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "from insightface.data import get_image as ins_get_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define variables\n",
    "drive_file_id = '1KOKqWBDMQzwgQwvvbQm06-DThmxys9Xk'  # replace 'FILE_ID' with your file's ID\n",
    "video_output = 'my_video.mp4'\n",
    "frame_folder = '/notebooks/frame_folder'\n",
    "swapped_folder = '/notebooks/swapped'\n",
    "character_folder = '/notebooks/character'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(frame_folder)\n",
    "shutil.rmtree(swapped_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert insightface.__version__ >= '0.7'\n",
    "\n",
    "\n",
    "# Create the frame folder if it doesn't exist\n",
    "if not os.path.exists(frame_folder):\n",
    "    os.makedirs(frame_folder)\n",
    "# Create the frame folder if it doesn't exist\n",
    "if not os.path.exists(swapped_folder):\n",
    "    os.makedirs(swapped_folder)\n",
    "# Your face swapping script\n",
    "app = FaceAnalysis(name='buffalo_l',providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "swapper = insightface.model_zoo.get_model('/notebooks/inswapper_128.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_first_face(image):\n",
    "    # If the image is a string (presumably a file path), read the image\n",
    "    if isinstance(image, str):\n",
    "        image = cv2.imread(image)\n",
    "\n",
    "    # Check if the image is a valid numpy array\n",
    "    if isinstance(image, np.ndarray):\n",
    "        source_faces = app.get(image)\n",
    "        source_faces = sorted(source_faces, key=lambda x: x.bbox[0])\n",
    "        if len(source_faces) == 0:\n",
    "            print(image)\n",
    "            assert False\n",
    "\n",
    "        return source_faces[0]\n",
    "    print(image)\n",
    "    assert False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://example.com/path_to_your_file\"  # replace with your file's URL\n",
    "response = requests.get(url)\n",
    "\n",
    "with open(video_output, 'wb') as f:  # replace with the path where you want to save the file\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download video from Google Drive\n",
    "url = f'https://drive.google.com/uc?id={drive_file_id}'\n",
    "gdown.download(url, video_output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete if swapped folder is not empty\n",
    "if  os.path.exists(character_folder):\n",
    "    shutil.rmtree(character_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "import datetime\n",
    "# Create the frame folder if it doesn't exist\n",
    "if not os.path.exists(character_folder):\n",
    "    os.makedirs(character_folder)\n",
    "if not os.path.exists(frame_folder):\n",
    "    os.makedirs(frame_folder)\n",
    "# Initialize the FaceAnalysis application\n",
    "\"\"\" app = FaceAnalysis(providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))  # Use GPU device 0 and input image size as (640, 640) \"\"\"\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_output)\n",
    "# Calculate frame rate (frames per second)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "# Initialize a list to store embeddings and face data for each detected face\n",
    "face_data = []\n",
    "count = 0\n",
    "# Loop through the video file frame by frame\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        # Calculate the time in minutes and seconds\n",
    "    time_in_milliseconds = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    frame_time = datetime.timedelta(milliseconds=time_in_milliseconds)\n",
    "    path = os.path.join(frame_folder, f\"{count}.jpg\")\n",
    "    cv2.imwrite(path, frame)  # save frame as JPEG file\n",
    "    count += 1\n",
    "    # Use the FaceAnalysis application to detect faces in the frame\n",
    "    faces = app.get(frame)\n",
    "\n",
    "    # For each detected face, extract the embedding, bounding box, and face image, and add them to the list\n",
    "    for face in faces:\n",
    "        if face.det_score < 0.1:\n",
    "            continue\n",
    "        face_embedding = face.embedding\n",
    "       \n",
    "        bbox = face.bbox.astype(int)\n",
    "        cropped_face = frame[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "    \n",
    "        if cropped_face.size > 0:\n",
    "            face_data.append({'label':'','frame':count,'time':frame_time,'face_embedding': face_embedding,'score':face.det_score,'normed_embedding': face.normed_embedding, 'bbox': bbox, 'image': cropped_face})\n",
    "            \n",
    "\n",
    "# Save the face_data to disk\n",
    "with open('face_data.pkl', 'wb') as f:\n",
    "    pickle.dump(face_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_similar(face1, face2, threshold=0.5):\n",
    "    # Extract normalized embeddings\n",
    "    embedding1 = face1.normed_embedding\n",
    "    embedding2 = face2.normed_embedding\n",
    "\n",
    "    # Compute the dot product (cosine similarity, because embeddings are normalized)\n",
    "    similarity = np.dot(embedding1, embedding2)\n",
    "\n",
    "    # Return True if the similarity is above the threshold, False otherwise\n",
    "    return similarity > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete if swapped folder is not empty\n",
    "if  os.path.exists(character_folder):\n",
    "    shutil.rmtree(character_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22\n",
      " 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46\n",
      " 47 48 49 50 51 52]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from imutils import build_montages\n",
    "from sklearn.cluster import DBSCAN\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "# Check if the directories exist\n",
    "if not os.path.exists(character_folder):\n",
    "    os.makedirs(character_folder)\n",
    "\n",
    "# Load face data\n",
    "with open('face_data.pkl', 'rb') as f:\n",
    "    face_data = pickle.load(f)\n",
    "times = np.array([d['time'].total_seconds() for d in face_data])\n",
    "times = times / np.max(times)\n",
    "\n",
    "\"\"\" # Extend your embeddings\n",
    "for i, d in enumerate(face_data):\n",
    "    d['normed_embedding'] = np.append(d['normed_embedding'], times[i]) \"\"\"\n",
    "embeddings = [d['normed_embedding'] for d in face_data]\n",
    "norm_data = normalize(embeddings, norm='l2')\n",
    "\n",
    "clustering = DBSCAN(eps=0.5, min_samples=6,metric=\"cosine\")\n",
    "clustering.fit(norm_data)\n",
    "\n",
    "labels = np.unique(clustering.labels_)\n",
    "print(labels)\n",
    "for label in labels:\n",
    "    # Skip the noise\n",
    "    if label == -1:\n",
    "        continue  \n",
    "\n",
    "    directory_path = os.path.join(character_folder, str(label))\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "\n",
    "    # Select samples associated with the current label\n",
    "    idxs = np.where(clustering.labels_ == label)[0]\n",
    "    idxs = np.random.choice(idxs, size=min(25, len(idxs)), replace=False)\n",
    "\n",
    "    faces = []\n",
    "    # loop over the sampled indexes\n",
    "    for i in idxs:\n",
    "        # Get the cropped face image from the 'image' key\n",
    "        face = face_data[i][\"image\"]\n",
    "        face_data[i][\"label\"] = str(label)\n",
    "        time_elapsed= face_data[i]['time']\n",
    "        # Calculate minutes and seconds\n",
    "        minutes = time_elapsed.total_seconds() // 60\n",
    "        seconds = time_elapsed.total_seconds() % 60\n",
    "\n",
    "        # Format the time string as MM:SS\n",
    "        frame_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "        # Force resize the face to 96x96 and then add it to the\n",
    "        # faces montage list\n",
    "        face = cv2.resize(face, (150, 150))\n",
    "        cv2.putText(face,frame_time, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "        faces.append(face)\n",
    "\n",
    "        # Save face image\n",
    "        image_path = os.path.join(directory_path, f\"{i}.jpg\")\n",
    "        cv2.imwrite(image_path, face)\n",
    "        \n",
    "        # Save embedding\n",
    "        face_embedding = face_data[i]['normed_embedding']\n",
    "        embedding_path = os.path.join(directory_path, f\"{i}.npy\")\n",
    "        np.save(embedding_path, face_embedding)\n",
    "    # Create a montage using 96x96 \"tiles\" with 5 rows and 5 columns\n",
    "    montage = build_montages(faces, (150, 150), (5, 5))[0]\n",
    "    \n",
    "    # Save the output montage\n",
    "    title = \"Face ID #{}\".format(label)\n",
    "    title = \"Unknown Faces\" if label == -1 else title\n",
    "    cv2.imwrite(os.path.join(directory_path, title+'.jpg'), montage)\n",
    "    new_face_data = new_face_data\n",
    "\n",
    "# Save the face_data to disk\n",
    "with open('face_data.pkl', 'wb') as f:\n",
    "    pickle.dump(face_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cluster: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd7200da5cb424e8caa2e06f913d851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c683cf0cf6847aaab122111e40b4f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='5', description='Name:', placeholder='Enter character name')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eabe296ca2e47f6b35e110684fecf6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Confirm', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from fastai.vision.all import *\n",
    "from pathlib import Path\n",
    "from PIL import Image as PilImage\n",
    "import shutil\n",
    "# Load face data\n",
    "with open('face_data.pkl', 'rb') as f:\n",
    "    face_data = pickle.load(f)\n",
    "\n",
    "# Load data\n",
    "path = Path(character_folder)\n",
    "\n",
    "# Only consider directories where the name is numeric\n",
    "folders = [dir for dir in path.iterdir() if dir.is_dir() and dir.name.isnumeric()]\n",
    "\n",
    "labels = [folder.name for folder in folders]\n",
    "\n",
    "# Create a dictionary to map old labels (folders) to new labels (characters)\n",
    "label_dict = {}\n",
    "\n",
    "# Define a generator to process one folder at a time\n",
    "def process_folders():\n",
    "    for label in labels:\n",
    "        # Get a list of all image files in the cluster\n",
    "        image_paths = list((path / label).glob('*.jpg'))\n",
    "        if not image_paths:\n",
    "            print(f\"No images found in cluster: {label}\")\n",
    "            continue\n",
    "        print(f\"Current cluster: {label}\")\n",
    "\n",
    "        # Get the resolution of each image\n",
    "        image_resolution = {}\n",
    "        for image_path in image_paths:\n",
    "            with PilImage.open(image_path) as img:\n",
    "                width, height = img.size\n",
    "                resolution = width * height  # resolution is defined as width * height\n",
    "                image_resolution[image_path] = resolution\n",
    "\n",
    "        # Sort images by resolution in descending order\n",
    "        sorted_image_paths = sorted(image_resolution, key=image_resolution.get, reverse=True)\n",
    "\n",
    "        # Display the largest image\n",
    "        with open(sorted_image_paths[0], \"rb\") as file:\n",
    "            image = file.read()\n",
    "            img_widget = widgets.Image(value=image, format='png', width=1000, height=400)  # You might want to adjust the size\n",
    "            display(img_widget)\n",
    "\n",
    "        # Ask the user to input the name of the character\n",
    "        name = widgets.Text(value=label, placeholder='Enter character name', description='Name:')\n",
    "        button = widgets.Button(description='Confirm')\n",
    "        display(name, button)\n",
    "\n",
    "        def on_button_clicked(b):\n",
    "            # Update the label dictionary\n",
    "            label_dict[label] = name.value\n",
    "            print(f'Character name confirmed: {name.value}')\n",
    "\n",
    "            # Rename the folder\n",
    "            old_name = Path(path / label)\n",
    "            new_name = Path(path / name.value)\n",
    "\n",
    "            # Update the label in the original face_data list\n",
    "            for f in face_data:\n",
    "                if 'label' in f and f['label'] == label:\n",
    "                    f['label'] = name.value\n",
    "\n",
    "            if new_name.exists():  # If the target directory exists\n",
    "                # Copy all .jpg files in the current folder to the target folder\n",
    "                for file in old_name.glob('*.jpg'):\n",
    "                    if old_name != new_name:\n",
    "                        shutil.copy(file, new_name / file.name)\n",
    "                # Copy all .npy files (embeddings) in the current folder to the target folder\n",
    "                for file in old_name.glob('*.npy'):\n",
    "                    if old_name != new_name:\n",
    "                        shutil.copy(file, new_name / file.name)\n",
    "                # Delete the current folder\n",
    "                shutil.rmtree(old_name)\n",
    "            else:\n",
    "                old_name.rename(new_name)\n",
    "            # Save the face_data to disk\n",
    "            with open('face_data.pkl', 'wb') as f:\n",
    "                pickle.dump(face_data, f)\n",
    "            # Proceed to the next cluster\n",
    "            clear_output(wait=True)\n",
    "            next(process)\n",
    "\n",
    "        button.on_click(on_button_clicked)\n",
    "  \n",
    "        # Yield control and wait for the next call\n",
    "        yield\n",
    "\n",
    "# Start the process\n",
    "process = process_folders()\n",
    "next(process)  # Display the first cluster\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9d9977b10e4a0289fcf09641bca91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=28, description='Frame:', max=899, min=28)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50fd0a9ea2c4a11a1165bfc752b358e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: f1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: f1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: f1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: f1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: f1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: f1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: m1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: m1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: m1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: m1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: m1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: m1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: m1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: m1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: m1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: m1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: m1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character name confirmed: m1\n"
     ]
    }
   ],
   "source": [
    "from hmac import new\n",
    "import pickle\n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image as PilImage\n",
    "import numpy as np\n",
    "import io\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from PIL import Image as PilImage\n",
    "from ipywidgets import HBox, VBox\n",
    "# Load face_data\n",
    "with open('face_data.pkl', 'rb') as f:\n",
    "    face_data = pickle.load(f)\n",
    "\n",
    "cap = cv2.VideoCapture(video_output)\n",
    "\n",
    "# Define path to the parent folder\n",
    "path = Path(character_folder)  # replace with your folder path\n",
    "\n",
    "# Define total frames for the slider\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Define an output widget for the frame display\n",
    "frame_output = widgets.Output()\n",
    "\n",
    "# Define a generator to process one frame at a time\n",
    "def process_frame(frame_number):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return  # end of video\n",
    "    # Convert frame (numpy array) to PIL image\n",
    "    frame_pil = PilImage.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Resize the image\n",
    "    base_width = 500\n",
    "    w_percent = (base_width / float(frame_pil.size[0]))\n",
    "    h_size = int((float(frame_pil.size[1]) * float(w_percent)))\n",
    "    frame_pil = frame_pil.resize((base_width, h_size))\n",
    "\n",
    "    # Convert PIL image to widget-compatible format\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    frame_pil.save(img_byte_arr, format='PNG')\n",
    "    frame_widget = widgets.Image(value=img_byte_arr.getvalue(), format='png')\n",
    "\n",
    "\n",
    "    # Clear the output widget\n",
    "    frame_output.clear_output()\n",
    "\n",
    "    # Write to the output widget\n",
    "    with frame_output:\n",
    "        # Display the frame number and full frame\n",
    "        print(f\"Frame number: {frame_number}\")\n",
    "        \"\"\"     display(frame_widget) \"\"\"\n",
    "\n",
    "        # Get face data corresponding to current frame\n",
    "        faces = [p for p in face_data if p[\"frame\"] == frame_number]\n",
    "        # Create a list to store cropped face widgets\n",
    "        face_widgets = []\n",
    "        # Process each face in the frame\n",
    "        for face in faces:\n",
    "            # Display the time\n",
    "            print(f\"Time: {face['time']}\")\n",
    "            cropped_face = face['image']\n",
    "\n",
    "            # Convert cropped_face (numpy array) to PIL image\n",
    "            cropped_face_pil = PilImage.fromarray(cropped_face)\n",
    "\n",
    "            # Convert PIL image to widget-compatible format\n",
    "            img_byte_arr = io.BytesIO()\n",
    "            cropped_face_pil.save(img_byte_arr, format='PNG')\n",
    "            cropped_face_widget = widgets.Image(value=img_byte_arr.getvalue(), format='png')\n",
    "\n",
    "\n",
    "            # Ask the user to input the name of the character\n",
    "            name = widgets.Text(value=str(face['label']), placeholder='Enter character name', description='Name:')\n",
    "            button = widgets.Button(description='Confirm')\n",
    "            \"\"\"     display(name, button) \"\"\"\n",
    "\n",
    "            def on_button_clicked(b):\n",
    "                # Update the label dictionary\n",
    "                label = name.value\n",
    "                for f in face_data:\n",
    "                    if f['frame'] == frame_number and np.array_equal(f['image'], face['image']):\n",
    "                        f['label'] = name.value\n",
    "                print(f'Character name confirmed: {name.value}')\n",
    "                face['label'] = name.value\n",
    "                # Rename the folder\n",
    "                old_name = Path(path / label)\n",
    "                new_name = Path(path / name.value)\n",
    "                if new_name.exists():  # If the target directory exists\n",
    "                    # Copy all .jpg files in the current folder to the target folder\n",
    "                    for file in old_name.glob('*.jpg'):\n",
    "                        if new_name != old_name:\n",
    "                            shutil.copy(file, new_name / file.name)\n",
    "                        # Copy all .npy files (embeddings) in the current folder to the target folder\n",
    "                    for file in old_name.glob('*.npy'):\n",
    "                        if new_name != old_name:\n",
    "                            shutil.copy(file, new_name / file.name)\n",
    "                        # Delete the current folder\n",
    "                    shutil.rmtree(old_name)\n",
    "                else:\n",
    "                    if not os.path.exists(new_name):\n",
    "                        os.mkdir(new_name)\n",
    "                    old_name.rename(new_name)\n",
    "\n",
    "                frame_output.clear_output(wait=True)\n",
    "                process_frame(frame_number)\n",
    "                with open('face_data.pkl', 'wb') as f:\n",
    "                    pickle.dump(face_data, f)\n",
    "                # Update the frame\n",
    "                frame_output.clear_output(wait=True)\n",
    "\n",
    "                # Get the faces in the current frame that have label '0'\n",
    "                faces_with_label_0 = [f for f in face_data if f['frame'] == frame_number and f['label'] == '0']\n",
    "\n",
    "                # If there are no more faces with label '0' in the current frame, proceed to the next frame\n",
    "                if not faces_with_label_0:\n",
    "                    next_frame_with_label_0 = [f for f in face_data if f['frame'] > frame_number and f['label'] == '0']\n",
    "                    if next_frame_with_label_0:\n",
    "                        next_frame_number = next_frame_with_label_0[0]['frame']\n",
    "                        slider.value = next_frame_number  # Update the slider value\n",
    "                    else:\n",
    "                        print('No more frames with label 0.')\n",
    "                else:\n",
    "                    process_frame(frame_number)\n",
    "\n",
    "            button.on_click(on_button_clicked)\n",
    "            # Create a vertical box (VBox) for each face, including the image, text field, and button\n",
    "            face_box = VBox([cropped_face_widget, name, button])\n",
    "\n",
    "            # Add the face box to the list\n",
    "            face_widgets.append(face_box)\n",
    "        if len(faces) == 0:\n",
    "            print(\"No face detected in this frame\")\n",
    "        # Display the cropped faces at the side of the main frame using HBox\n",
    "        display(HBox([frame_widget] + face_widgets))\n",
    "        \n",
    "# At the start of your code, add the following line to get the first frame that has a label '0'\n",
    "first_frame_with_label_0 = min([f['frame'] for f in face_data if f['label'] == '0'], default=0)\n",
    "# Define a slider to navigate frames\n",
    "slider = widgets.IntSlider(min=first_frame_with_label_0, max=total_frames, step=1, description='Frame:')\n",
    "\n",
    "def on_slider_change(change):\n",
    "    process_frame(change['new'])\n",
    "\n",
    "slider.observe(on_slider_change, names='value')\n",
    "\n",
    "# Display the slider and frame_output widget\n",
    "display(slider, frame_output)\n",
    "\n",
    "\n",
    "# ...\n",
    "\n",
    "# Process the first frame with label '0'\n",
    "process_frame(first_frame_with_label_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = []\n",
    "for label in os.listdir(character_folder):\n",
    "    for filename in os.listdir(os.path.join(character_folder, label)):\n",
    "        if filename.endswith('.npy'):  # check if the file is an image\n",
    "            # read the image\n",
    "            img_path = os.path.join(character_folder, label, filename)\n",
    "            embedding = np.load(img_path)\n",
    "            data.append({'embedding': embedding, 'label': label})\n",
    "                \n",
    "\n",
    "# create a dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Separate features and target\n",
    "X = np.array(df['embedding'].to_list()) # Convert list of embeddings back to numpy array\n",
    "y = df['label'].values\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "knn = KNeighborsClassifier(n_neighbors=4,metric='euclidean')\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model\n",
    "accuracy = knn.score(X_val, y_val)\n",
    "print(f'Validation accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import pickle\n",
    "\n",
    "# Open the pickle file and load the face data\n",
    "with open('face_data.pkl', 'rb') as f:\n",
    "    face_data = pickle.load(f)\n",
    "\n",
    "# Now you can use the loaded face data. For example, you can extract all embeddings:\n",
    "embeddings = np.array([data['face_embedding'] for data in face_data])\n",
    "\n",
    "\n",
    "# Determine the optimal number of clusters, you might want to adjust this\n",
    "n_clusters = 20\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=n_clusters).fit(embeddings)\n",
    "\n",
    "# For each cluster center, find the closest face (in terms of Euclidean distance in the embedding space)\n",
    "# and save it as a representative of the cluster (i.e., the character)\n",
    "character_index= 0\n",
    "previous = []\n",
    "for i, center in enumerate(kmeans.cluster_centers_):\n",
    "    distances = np.linalg.norm(embeddings - center, axis=1)\n",
    "    closest_face_index = np.argmin(distances)\n",
    "    bbox = face_data[closest_face_index][\"bbox\"]\n",
    "    cropped_face = face_data[closest_face_index][\"image\"]\n",
    "    found = False\n",
    "    for index,j in enumerate(previous):\n",
    "        similarity = np.dot(face_data[closest_face_index][\"normed_embedding\"], j)\n",
    "        print(i, index,similarity)\n",
    "        if similarity > 0.35:\n",
    "            print(\"found same face\")\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        cv2.imwrite(f'{character_folder}/character_{character_index}.jpg',cropped_face)   \n",
    "        previous.append(face_data[closest_face_index][\"normed_embedding\"])\n",
    "        character_index += 1\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# The input for NearestNeighbors will be the cluster centers.\n",
    "# These act as the \"labels\" for each cluster.\n",
    "nn_model = NearestNeighbors(n_neighbors=3, metric='cosine')\n",
    "nn_model.fit(kmeans.cluster_centers_) \"\"\"\n",
    "def classify_face(embedding):\n",
    "    predicted_label = knn.predict([embedding])\n",
    "    predicted_label_str = le.inverse_transform(predicted_label)\n",
    "    return predicted_label_str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(frame_folder):\n",
    "    os.makedirs(frame_folder)\n",
    "# Extract frames from video\n",
    "vidcap = cv2.VideoCapture(video_output)\n",
    "success, image = vidcap.read()\n",
    "count = 0\n",
    "target_imgs = []  # a list of file paths to images of the target faces\n",
    "while success:\n",
    "    path = os.path.join(frame_folder, f\"{count}.jpg\")\n",
    "    target_imgs.append(path)\n",
    "    cv2.imwrite(path, image)  # save frame as JPEG file\n",
    "    success, image = vidcap.read()\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete if swapped folder is not empty\n",
    "if  os.path.exists(swapped_folder):\n",
    "    shutil.rmtree(swapped_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the frame folder if it doesn't exist\n",
    "if not os.path.exists(swapped_folder):\n",
    "    os.makedirs(swapped_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "import natsort\n",
    "\n",
    "swappings ={\n",
    "   'm':get_first_face('/notebooks/1629085462605.jpeg'),\n",
    "   'b':get_first_face('/notebooks/bcp.png'),\n",
    "   'd':get_first_face('/notebooks/DSCAAZZEA.png'),\n",
    "   'l2':get_first_face('/notebooks/2023-07-03 22.46.08.jpg'),\n",
    "   'la':get_first_face('/notebooks/2023-07-03 22.47.10.jpg'),\n",
    "   'jo':get_first_face('/notebooks/jocp.png'),\n",
    "   'g':get_first_face('/notebooks/gacp.png'),\n",
    "   'je':get_first_face('/notebooks/2023-07-03 22.47.24.jpg')\n",
    "}\n",
    "targets={\n",
    " 'f': None\n",
    "}\n",
    "\n",
    "source_face = get_first_face('/notebooks/DSC06729.JPG')\n",
    "image_files = glob.glob(os.path.join(frame_folder, '*.jpg'))  # get all jpg files in the frame folder\n",
    "# Sort the file names using natural sorting\n",
    "image_files = natsort.natsorted(image_files)\n",
    "print(len(image_files))\n",
    "# Initialize an empty dictionary to store the attribution of faces to people\n",
    "attribution = {}\n",
    "unused_keys = list(swappings.keys())\n",
    "for key in list(targets.keys()):\n",
    "    value = targets[key]\n",
    "    if value is not None:\n",
    "        unused_keys.remove(value)\n",
    "# Define a deque for each face in the swappings dictionary with maxlen equal to the size of your smoothing window\n",
    "smoothing_window_size = 5  # Or however large you want your smoothing window to be\n",
    "embeddings_deques = collections.defaultdict(lambda: collections.deque(maxlen=smoothing_window_size))\n",
    "\n",
    "# Now, in your loop over the image files, for each face you detect:\n",
    "for img_file in image_files:\n",
    "    img = cv2.imread(img_file)\n",
    "    faces = app.get(img)\n",
    "    faces = sorted(faces, key=lambda x: x.bbox[0])\n",
    "    res = img.copy()\n",
    "    for face in faces:\n",
    "        if face.det_score < 0.1:\n",
    "            continue\n",
    "        found = False\n",
    "        index = classify_face(face.normed_embedding)\n",
    "        if index in targets:\n",
    "            found = True\n",
    "            value = targets[index]\n",
    "            if value is not None:\n",
    "                res = swapper.get(res, face, swappings[value], paste_back=True)\n",
    "                break\n",
    "\n",
    "        if not found:\n",
    "            # Add the new embedding to the deque for that face\n",
    "            embeddings_deques[index].append(face.normed_embedding)\n",
    "            # Now use the mean of the embeddings in the deque to classify the face\n",
    "            avg_embedding = np.mean(embeddings_deques[index], axis=0)\n",
    "            index = classify_face(avg_embedding)\n",
    "\n",
    "            if index in attribution:\n",
    "                found = True\n",
    "                res = swapper.get(res, face, swappings[attribution[index]], paste_back=True)\n",
    "            else:\n",
    "                print(\"index not found :\" ,index)\n",
    "        if not found:\n",
    "            if len(unused_keys) == 0:  # If all faces have been used, reset the list\n",
    "                unused_keys = list(swappings.keys())\n",
    "                for key in list(targets.keys()):\n",
    "                    if key in unused_keys:\n",
    "                        unused_keys.remove(key)\n",
    "            random_key = random.choice(unused_keys)\n",
    "            unused_keys.remove(random_key)\n",
    "            attribution[index] = random_key\n",
    "            print(\"index \",index,\" attribute to \",random_key, \" frame \", osp.basename(img_file))\n",
    "            random_value = swappings[random_key]\n",
    "            res = swapper.get(res, face, random_value, paste_back=True)\n",
    "    cv2.imwrite(osp.join(swapped_folder, osp.basename(img_file)), res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "output_video = \"/notebooks/output.mp4\"\n",
    "video = cv2.VideoCapture(video_output)\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "video.release()\n",
    "\n",
    "# Get the processed images\n",
    "processed_images = glob.glob(os.path.join(swapped_folder, '*.jpg'))\n",
    "\n",
    "# Sort the processed images (this may be necessary depending on how your files are named)\n",
    "processed_images.sort()\n",
    "print(len(processed_images))\n",
    "# Initialize the video writer\n",
    "height, width, _ = cv2.imread(processed_images[0]).shape\n",
    "print(height, width)\n",
    "\n",
    "# Define the command\n",
    "command = f'ffmpeg -y -r {fps} -s {width}x{height} -i {swapped_folder}/%01d.jpg -vcodec libx264 -crf 25 -pix_fmt yuv420p {output_video}'\n",
    "\n",
    "# Execute the command\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "temp_audio_file = '/notebooks/temp_audio.aac'\n",
    "\n",
    "# Remove temporary audio file if it exists\n",
    "if os.path.exists(temp_audio_file):\n",
    "    os.remove(temp_audio_file)\n",
    "\n",
    "# Remove output video with audio file if it exists\n",
    "output_with_audio_file = '/notebooks/output_with_audio.mp4'\n",
    "if os.path.exists(output_with_audio_file):\n",
    "    os.remove(output_with_audio_file)\n",
    "\n",
    "# Extract audio from original video and save it as a temporary audio file\n",
    "audio_extraction_command = f'ffmpeg -y -i {video_output} -vn -acodec aac -strict -2 {temp_audio_file}'\n",
    "subprocess.run(audio_extraction_command, shell=True)\n",
    "\n",
    "# Combine swapped video with original audio\n",
    "video_combination_command = f'ffmpeg -y -i {output_video} -i {temp_audio_file} -c:v copy -c:a copy -map 0:v:0 -map 1:a:0 {output_with_audio_file}'\n",
    "subprocess.run(video_combination_command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "\n",
    "# path to the video file\n",
    "video_path = output_with_audio_file\n",
    "\n",
    "# specify the start and end times in seconds\n",
    "# start time as (minutes, seconds)\n",
    "start_time_min_sec = (0, 0)  # 2 minutes 30 seconds\n",
    "start_time = start_time_min_sec[0]*60 + start_time_min_sec[1]\n",
    "\n",
    "# end time as (minutes, seconds)\n",
    "end_time_min_sec = (1, 40)  # 3 minutes 45 seconds\n",
    "end_time = end_time_min_sec[0]*60 + end_time_min_sec[1]\n",
    "\n",
    "# output file path\n",
    "output_path = \"/notebooks/split.mp4\"\n",
    "\n",
    "# extract subclip\n",
    "ffmpeg_extract_subclip(video_path, start_time, end_time, targetname=output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
