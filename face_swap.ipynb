{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U insightface onnxruntime-gpu  numpy fastai pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U gdown moviepy ffmpeg insightface natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import cv2\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip,AudioFileClip\n",
    "import glob\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "from insightface.data import get_image as ins_get_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define variables\n",
    "drive_file_id = '1ILta1DA26-gdNK9opGtZa6NaT2RuDj1_'  # replace 'FILE_ID' with your file's ID\n",
    "video_output = 'my_video.mp4'\n",
    "frame_folder = '/notebooks/frame_folder'\n",
    "swapped_folder = '/notebooks/swapped'\n",
    "character_folder = '/notebooks/character'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(frame_folder)\n",
    "shutil.rmtree(swapped_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert insightface.__version__ >= '0.7'\n",
    "\n",
    "\n",
    "# Create the frame folder if it doesn't exist\n",
    "if not os.path.exists(frame_folder):\n",
    "    os.makedirs(frame_folder)\n",
    "# Create the frame folder if it doesn't exist\n",
    "if not os.path.exists(swapped_folder):\n",
    "    os.makedirs(swapped_folder)\n",
    "# Your face swapping script\n",
    "app = FaceAnalysis(name='buffalo_l')\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "swapper = insightface.model_zoo.get_model('/notebooks/inswapper_128.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_first_face(image):\n",
    "    # If the image is a string (presumably a file path), read the image\n",
    "    if isinstance(image, str):\n",
    "        image = cv2.imread(image)\n",
    "\n",
    "    # Check if the image is a valid numpy array\n",
    "    if isinstance(image, np.ndarray):\n",
    "        source_faces = app.get(image)\n",
    "        source_faces = sorted(source_faces, key=lambda x: x.bbox[0])\n",
    "        if len(source_faces) == 0:\n",
    "            print(image)\n",
    "            assert False\n",
    "\n",
    "        return source_faces[0]\n",
    "    print(image)\n",
    "    assert False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://example.com/path_to_your_file\"  # replace with your file's URL\n",
    "response = requests.get(url)\n",
    "\n",
    "with open(video_output, 'wb') as f:  # replace with the path where you want to save the file\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download video from Google Drive\n",
    "url = f'https://drive.google.com/uc?id={drive_file_id}'\n",
    "gdown.download(url, video_output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete if swapped folder is not empty\n",
    "if  os.path.exists(character_folder):\n",
    "    shutil.rmtree(character_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "\n",
    "# Create the frame folder if it doesn't exist\n",
    "if not os.path.exists(character_folder):\n",
    "    os.makedirs(character_folder)\n",
    "# Initialize the FaceAnalysis application\n",
    "app = FaceAnalysis(providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))  # Use GPU device 0 and input image size as (640, 640)\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_output)\n",
    "# Initialize a list to store embeddings and face data for each detected face\n",
    "face_data = []\n",
    "count = 0\n",
    "# Loop through the video file frame by frame\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    path = os.path.join(frame_folder, f\"{count}.jpg\")\n",
    "    cv2.imwrite(path, image)  # save frame as JPEG file\n",
    "    count += 1\n",
    "    # Use the FaceAnalysis application to detect faces in the frame\n",
    "    faces = app.get(frame)\n",
    "\n",
    "    # For each detected face, extract the embedding, bounding box, and face image, and add them to the list\n",
    "    for face in faces:\n",
    "        face_embedding = face.embedding\n",
    "       \n",
    "        bbox = face.bbox.astype(int)\n",
    "        cropped_face = frame[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "        if cropped_face.size > 0:\n",
    "            face_data.append({'face_embedding': face_embedding,'normed_embedding': face.normed_embedding, 'bbox': bbox, 'image': cropped_face})\n",
    "            \n",
    "\n",
    "# Save the face_data to disk\n",
    "with open('face_data.pkl', 'wb') as f:\n",
    "    pickle.dump(face_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_similar(face1, face2, threshold=0.5):\n",
    "    # Extract normalized embeddings\n",
    "    embedding1 = face1.normed_embedding\n",
    "    embedding2 = face2.normed_embedding\n",
    "\n",
    "    # Compute the dot product (cosine similarity, because embeddings are normalized)\n",
    "    similarity = np.dot(embedding1, embedding2)\n",
    "\n",
    "    # Return True if the similarity is above the threshold, False otherwise\n",
    "    return similarity > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import pickle\n",
    "if not os.path.exists(character_folder):\n",
    "    os.makedirs(character_folder)\n",
    "# Load face data\n",
    "with open('face_data.pkl', 'rb') as f:\n",
    "    face_data = pickle.load(f)\n",
    "\n",
    "# Perform clustering\n",
    "embeddings = [d['normed_embedding'] for d in face_data]\n",
    "clustering = DBSCAN(eps=0.45,metric=\"cosine\", min_samples=4).fit(embeddings)\n",
    "\n",
    "# Create directories for each cluster (each representing a character)\n",
    "labels = set(clustering.labels_)\n",
    "for label in labels:\n",
    "    if label == -1:\n",
    "        continue  # Skip the noise\n",
    "    directory_path = os.path.join(character_folder, str(label))\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "\n",
    "\n",
    "# Save faces into corresponding directories\n",
    "for i, label in enumerate(clustering.labels_):\n",
    "    if label == -1:\n",
    "        continue  # Skip the noise\n",
    "    directory_path = os.path.join(character_folder, str(label))\n",
    "    face_image = face_data[i]['image']\n",
    "    image_path = os.path.join(directory_path, f\"{i}.jpg\")\n",
    "\n",
    "    cv2.imwrite(image_path, face_image)\n",
    "    # Save embedding\n",
    "    face_embedding = face_data[i]['normed_embedding']\n",
    "    embedding_path = os.path.join(directory_path, f\"{i}.npy\")\n",
    "    np.save(embedding_path, face_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from fastai.vision.all import *\n",
    "from pathlib import Path\n",
    "from PIL import Image as PilImage\n",
    "\n",
    "# Load data\n",
    "path = Path(character_folder)\n",
    "\n",
    "# Only consider directories where the name is numeric\n",
    "folders = [dir for dir in path.iterdir() if dir.is_dir() and dir.name.isnumeric()]\n",
    "\n",
    "labels = [folder.name for folder in folders]\n",
    "\n",
    "# Create a dictionary to map old labels (folders) to new labels (characters)\n",
    "label_dict = {}\n",
    "\n",
    "# Define a generator to process one folder at a time\n",
    "def process_folders():\n",
    "    for label in labels:\n",
    "        # Get a list of all image files in the cluster\n",
    "        image_paths = list((path / label).glob('*.jpg'))\n",
    "        if not image_paths:\n",
    "            print(f\"No images found in cluster: {label}\")\n",
    "            continue\n",
    "        print(f\"Current cluster: {label}\")\n",
    "\n",
    "        # Get the resolution of each image\n",
    "        image_resolution = {}\n",
    "        for image_path in image_paths:\n",
    "            with PilImage.open(image_path) as img:\n",
    "                width, height = img.size\n",
    "                resolution = width * height  # resolution is defined as width * height\n",
    "                image_resolution[image_path] = resolution\n",
    "\n",
    "        # Sort images by resolution in descending order\n",
    "        sorted_image_paths = sorted(image_resolution, key=image_resolution.get, reverse=True)\n",
    "        \n",
    "        # Group images into rows for display, with four images per row\n",
    "        rows = []\n",
    "        for i in range(0, len(sorted_image_paths), 4):\n",
    "            row = []\n",
    "            for image_path in sorted_image_paths[i:i+4]:\n",
    "                with open(image_path, \"rb\") as file:\n",
    "                    image = file.read()\n",
    "                    img_widget = widgets.Image(value=image, format='png', width=200, height=200)  # You might want to adjust the size\n",
    "                    row.append(img_widget)\n",
    "            rows.append(widgets.HBox(row))\n",
    "        \n",
    "        # Display the gallery\n",
    "        display(widgets.VBox(rows))\n",
    "\n",
    "        # Ask the user to input the name of the character\n",
    "        name = widgets.Text(value='', placeholder='Enter character name', description='Name:')\n",
    "        button = widgets.Button(description='Confirm')\n",
    "        display(name, button)\n",
    "\n",
    "        def on_button_clicked(b):\n",
    "            # Update the label dictionary\n",
    "            label_dict[label] = name.value\n",
    "            print(f'Character name confirmed: {name.value}')\n",
    "            \n",
    "            # Rename the folder\n",
    "            old_name = Path(path / label)\n",
    "            new_name = Path(path / name.value)\n",
    "            if new_name:  # Make sure the new_name exists\n",
    "                if new_name.exists():  # If the target directory exists\n",
    "                    # Copy all .jpg files in the current folder to the target folder\n",
    "                    for file in old_name.glob('*.jpg'):\n",
    "                        shutil.copy(file, new_name / file.name)\n",
    "                    # Copy all .npy files (embeddings) in the current folder to the target folder\n",
    "                    for file in old_name.glob('*.npy'):\n",
    "                        shutil.copy(file, new_name / file.name)\n",
    "                    # Delete the current folder\n",
    "                    shutil.rmtree(old_name)\n",
    "                else:\n",
    "                    # If target directory does not exist, simply rename\n",
    "                    old_name.rename(new_name)\n",
    "            \n",
    "            # Proceed to the next cluster\n",
    "            clear_output(wait=True)\n",
    "            next(process)\n",
    "\n",
    "        button.on_click(on_button_clicked)\n",
    "        \n",
    "        # Yield control and wait for the next call\n",
    "        yield\n",
    "\n",
    "# Start the process\n",
    "process = process_folders()\n",
    "next(process)  # Display the first cluster\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = []\n",
    "for label in os.listdir(character_folder):\n",
    "    for filename in os.listdir(os.path.join(character_folder, label)):\n",
    "        if filename.endswith('.npy'):  # check if the file is an image\n",
    "            # read the image\n",
    "            img_path = os.path.join(character_folder, label, filename)\n",
    "            embedding = np.load(img_path)\n",
    "            data.append({'embedding': embedding, 'label': label})\n",
    "                \n",
    "\n",
    "# create a dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df.sample(1)\n",
    "# Separate features and target\n",
    "X = np.array(df['embedding'].to_list()) # Convert list of embeddings back to numpy array\n",
    "y = df['label'].values\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model\n",
    "accuracy = knn.score(X_val, y_val)\n",
    "print(f'Validation accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import pickle\n",
    "\n",
    "# Open the pickle file and load the face data\n",
    "with open('face_data.pkl', 'rb') as f:\n",
    "    face_data = pickle.load(f)\n",
    "\n",
    "# Now you can use the loaded face data. For example, you can extract all embeddings:\n",
    "embeddings = np.array([data['face_embedding'] for data in face_data])\n",
    "\n",
    "\n",
    "# Determine the optimal number of clusters, you might want to adjust this\n",
    "n_clusters = 20\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=n_clusters).fit(embeddings)\n",
    "\n",
    "# For each cluster center, find the closest face (in terms of Euclidean distance in the embedding space)\n",
    "# and save it as a representative of the cluster (i.e., the character)\n",
    "character_index= 0\n",
    "previous = []\n",
    "for i, center in enumerate(kmeans.cluster_centers_):\n",
    "    distances = np.linalg.norm(embeddings - center, axis=1)\n",
    "    closest_face_index = np.argmin(distances)\n",
    "    bbox = face_data[closest_face_index][\"bbox\"]\n",
    "    cropped_face = face_data[closest_face_index][\"image\"]\n",
    "    found = False\n",
    "    for index,j in enumerate(previous):\n",
    "        similarity = np.dot(face_data[closest_face_index][\"normed_embedding\"], j)\n",
    "        print(i, index,similarity)\n",
    "        if similarity > 0.35:\n",
    "            print(\"found same face\")\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        cv2.imwrite(f'{character_folder}/character_{character_index}.jpg',cropped_face)   \n",
    "        previous.append(face_data[closest_face_index][\"normed_embedding\"])\n",
    "        character_index += 1\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# The input for NearestNeighbors will be the cluster centers.\n",
    "# These act as the \"labels\" for each cluster.\n",
    "nn_model = NearestNeighbors(n_neighbors=3, metric='cosine')\n",
    "nn_model.fit(kmeans.cluster_centers_) \"\"\"\n",
    "def classify_face(embedding):\n",
    "    predicted_label = knn.predict([embedding])\n",
    "    predicted_label_str = le.inverse_transform(predicted_label)\n",
    "    return predicted_label_str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract frames from video\n",
    "vidcap = cv2.VideoCapture(video_output)\n",
    "success, image = vidcap.read()\n",
    "count = 0\n",
    "target_imgs = []  # a list of file paths to images of the target faces\n",
    "while success:\n",
    "    path = os.path.join(frame_folder, f\"{count}.jpg\")\n",
    "    target_imgs.append(path)\n",
    "    cv2.imwrite(path, image)  # save frame as JPEG file\n",
    "    success, image = vidcap.read()\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete if swapped folder is not empty\n",
    "if  os.path.exists(swapped_folder):\n",
    "    shutil.rmtree(swapped_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the frame folder if it doesn't exist\n",
    "if not os.path.exists(swapped_folder):\n",
    "    os.makedirs(swapped_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import natsort\n",
    "\n",
    "swappings ={\n",
    "   'm':get_first_face('/notebooks/1629085462605.jpeg'),\n",
    "   'b':get_first_face('/notebooks/bcp.png'),\n",
    "   'd':get_first_face('/notebooks/DSCAAZZEA.png'),\n",
    "   'l2':get_first_face('/notebooks/2023-07-03 22.46.08.jpg'),\n",
    "   'la':get_first_face('/notebooks/2023-07-03 22.47.10.jpg'),\n",
    "   'jo':get_first_face('/notebooks/jocp.png'),\n",
    "   'g':get_first_face('/notebooks/gacp.png'),\n",
    "   'je':get_first_face('/notebooks/2023-07-03 22.47.24.jpg')\n",
    "}\n",
    "targets={\n",
    "\n",
    "}\n",
    "\n",
    "source_face = get_first_face('/notebooks/DSC06729.JPG')\n",
    "image_files = glob.glob(os.path.join(frame_folder, '*.jpg'))  # get all jpg files in the frame folder\n",
    "# Sort the file names using natural sorting\n",
    "image_files = natsort.natsorted(image_files)\n",
    "print(len(image_files))\n",
    "# Initialize an empty dictionary to store the attribution of faces to people\n",
    "attribution = {}\n",
    "unused_keys = list(swappings.keys())\n",
    "for key in list(targets.keys()):\n",
    "    value = targets[key]\n",
    "    if value is not None:\n",
    "        unused_keys.remove(value)\n",
    "# Process each image and save the result\n",
    "for img_file in image_files:\n",
    "    img = cv2.imread(img_file)\n",
    "    faces = app.get(img)\n",
    "    faces = sorted(faces, key=lambda x: x.bbox[0])\n",
    "    res = img.copy()\n",
    "    for face in faces:\n",
    "        found = False\n",
    "        index = classify_face(face.normed_embedding)\n",
    "        if index in targets:\n",
    "            found = True\n",
    "            value = targets[index]\n",
    "            if value is not None:\n",
    "                res = swapper.get(res, face, swappings[value], paste_back=True)\n",
    "                break        \n",
    "        if not found:\n",
    "            \"\"\" # Check if the face is already attributed to a person\n",
    "            index = classify_face(face.normed_embedding) \"\"\"\n",
    "            if index in attribution:\n",
    "                found = True\n",
    "                res = swapper.get(res, face, swappings[attribution[index]], paste_back=True)\n",
    "            else:\n",
    "                print(\"index not found :\" ,index)\n",
    "        if not found:\n",
    "            if len(unused_keys) == 0:  # If all faces have been used, reset the list\n",
    "                unused_keys = list(swappings.keys())\n",
    "                for key in list(targets.keys()):\n",
    "                    if key in unused_keys:\n",
    "                        unused_keys.remove(key)\n",
    "            random_key = random.choice(unused_keys)\n",
    "            unused_keys.remove(random_key)\n",
    "            \"\"\" index = classify_face(face.normed_embedding) \"\"\"\n",
    "            attribution[index] = random_key\n",
    "            print(\"index \",index,\" attribute to \",random_key, \" frame \", osp.basename(img_file))\n",
    "            random_value = swappings[random_key]\n",
    "            res = swapper.get(res, face, random_value, paste_back=True)\n",
    "    cv2.imwrite(osp.join(swapped_folder, osp.basename(img_file)), res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "output_video = \"/notebooks/output.mp4\"\n",
    "video = cv2.VideoCapture(video_output)\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "video.release()\n",
    "\n",
    "# Get the processed images\n",
    "processed_images = glob.glob(os.path.join(swapped_folder, '*.jpg'))\n",
    "\n",
    "# Sort the processed images (this may be necessary depending on how your files are named)\n",
    "processed_images.sort()\n",
    "print(len(processed_images))\n",
    "# Initialize the video writer\n",
    "height, width, _ = cv2.imread(processed_images[0]).shape\n",
    "print(height, width)\n",
    "\n",
    "# Define the command\n",
    "command = f'ffmpeg -y -r {fps} -s {width}x{height} -i {swapped_folder}/%01d.jpg -vcodec libx264 -crf 25 -pix_fmt yuv420p {output_video}'\n",
    "\n",
    "# Execute the command\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "temp_audio_file = '/notebooks/temp_audio.aac'\n",
    "\n",
    "# Remove temporary audio file if it exists\n",
    "if os.path.exists(temp_audio_file):\n",
    "    os.remove(temp_audio_file)\n",
    "\n",
    "# Remove output video with audio file if it exists\n",
    "output_with_audio_file = '/notebooks/output_with_audio.mp4'\n",
    "if os.path.exists(output_with_audio_file):\n",
    "    os.remove(output_with_audio_file)\n",
    "\n",
    "# Extract audio from original video and save it as a temporary audio file\n",
    "audio_extraction_command = f'ffmpeg -y -i {video_output} -vn -acodec aac -strict -2 {temp_audio_file}'\n",
    "subprocess.run(audio_extraction_command, shell=True)\n",
    "\n",
    "# Combine swapped video with original audio\n",
    "video_combination_command = f'ffmpeg -y -i {output_video} -i {temp_audio_file} -c:v copy -c:a copy -map 0:v:0 -map 1:a:0 {output_with_audio_file}'\n",
    "subprocess.run(video_combination_command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "\n",
    "# path to the video file\n",
    "video_path = output_with_audio_file\n",
    "\n",
    "# specify the start and end times in seconds\n",
    "# start time as (minutes, seconds)\n",
    "start_time_min_sec = (0, 0)  # 2 minutes 30 seconds\n",
    "start_time = start_time_min_sec[0]*60 + start_time_min_sec[1]\n",
    "\n",
    "# end time as (minutes, seconds)\n",
    "end_time_min_sec = (1, 40)  # 3 minutes 45 seconds\n",
    "end_time = end_time_min_sec[0]*60 + end_time_min_sec[1]\n",
    "\n",
    "# output file path\n",
    "output_path = \"/notebooks/split.mp4\"\n",
    "\n",
    "# extract subclip\n",
    "ffmpeg_extract_subclip(video_path, start_time, end_time, targetname=output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
