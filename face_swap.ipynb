{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting insightface\n",
      "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting onnxruntime-gpu\n",
      "  Downloading onnxruntime_gpu-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.23.1)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.25.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.7 MB)\n",
      "Requirement already satisfied: fastai in /usr/local/lib/python3.9/dist-packages (2.7.9)\n",
      "Collecting fastai\n",
      "  Downloading fastai-2.7.12-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.1/233.1 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (9.2.0)\n",
      "Collecting pillow\n",
      "  Downloading Pillow-10.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from insightface) (3.5.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from insightface) (2.28.1)\n",
      "Collecting onnx\n",
      "  Downloading onnx-1.14.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from insightface) (1.8.1)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (from insightface) (0.29.30)\n",
      "Collecting easydict\n",
      "  Downloading easydict-1.10.tar.gz (6.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting albumentations\n",
      "  Downloading albumentations-1.3.1-py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting prettytable\n",
      "  Downloading prettytable-3.8.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from insightface) (1.1.1)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from insightface) (0.19.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from insightface) (4.64.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from onnxruntime-gpu) (3.19.4)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime-gpu) (1.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from onnxruntime-gpu) (21.3)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from fastai) (5.3.1)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.9/dist-packages (from fastai) (0.0.7)\n",
      "Requirement already satisfied: torch<2.1,>=1.7 in /usr/local/lib/python3.9/dist-packages (from fastai) (1.12.0+cu116)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.9/dist-packages (from fastai) (0.13.0+cu116)\n",
      "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.9/dist-packages (from fastai) (3.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from fastai) (1.4.3)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (from fastai) (22.2.2)\n",
      "Collecting fastcore<1.6,>=1.5.29\n",
      "  Downloading fastcore-1.5.29-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.9/dist-packages (from fastai) (1.0.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (8.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (63.1.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (0.9.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (2.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (2.4.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (0.6.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (3.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (1.9.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (2.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (3.0.9)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (3.1.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (1.0.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (0.4.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (1.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging->onnxruntime-gpu) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->insightface) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->insightface) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->insightface) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->insightface) (2019.11.28)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch<2.1,>=1.7->fastai) (4.3.0)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->insightface) (2.19.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->insightface) (1.3.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image->insightface) (2022.5.4)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image->insightface) (2.8.4)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.24.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->insightface) (1.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->insightface) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->insightface) (4.34.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->insightface) (2.8.2)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->fastai) (2022.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prettytable->insightface) (0.2.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->insightface) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->insightface) (1.1.0)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from pathy>=0.3.5->spacy<4->fastai) (5.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.14.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai) (0.7.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.5.0,>=0.3.0->spacy<4->fastai) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<4->fastai) (2.1.1)\n",
      "Building wheels for collected packages: insightface, easydict\n",
      "  Building wheel for insightface (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for insightface: filename=insightface-0.7.3-cp39-cp39-linux_x86_64.whl size=1053495 sha256=bdd4aad03919fc70114dc6838cf5fcf4e5726cad6308cecc79593b1fd3c4104c\n",
      "  Stored in directory: /root/.cache/pip/wheels/36/d1/8d/4994a23418af46d1edf9eb83d16c08c68314b79d9074b5d30a\n",
      "  Building wheel for easydict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for easydict: filename=easydict-1.10-py3-none-any.whl size=6491 sha256=60c02b41a0bee750745000c86c81e42c9b957edbf7e5b48a0eb3ad0b241bdf04\n",
      "  Stored in directory: /root/.cache/pip/wheels/0d/9a/a9/02f3a5f0c6b2c57184661770360c58db8166f5c877780e98f2\n",
      "Successfully built insightface easydict\n",
      "Installing collected packages: mpmath, easydict, sympy, protobuf, prettytable, pillow, numpy, humanfriendly, opencv-python-headless, onnx, fastcore, coloredlogs, onnxruntime-gpu, qudida, fastai, albumentations, insightface\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.4\n",
      "    Uninstalling protobuf-3.19.4:\n",
      "      Successfully uninstalled protobuf-3.19.4\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 9.2.0\n",
      "    Uninstalling Pillow-9.2.0:\n",
      "      Successfully uninstalled Pillow-9.2.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.1\n",
      "    Uninstalling numpy-1.23.1:\n",
      "      Successfully uninstalled numpy-1.23.1\n",
      "  Attempting uninstall: fastcore\n",
      "    Found existing installation: fastcore 1.5.27\n",
      "    Uninstalling fastcore-1.5.27:\n",
      "      Successfully uninstalled fastcore-1.5.27\n",
      "  Attempting uninstall: fastai\n",
      "    Found existing installation: fastai 2.7.9\n",
      "    Uninstalling fastai-2.7.9:\n",
      "      Successfully uninstalled fastai-2.7.9\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.4 which is incompatible.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed albumentations-1.3.1 coloredlogs-15.0.1 easydict-1.10 fastai-2.7.12 fastcore-1.5.29 humanfriendly-10.0 insightface-0.7.3 mpmath-1.3.0 numpy-1.24.4 onnx-1.14.0 onnxruntime-gpu-1.15.1 opencv-python-headless-4.8.0.74 pillow-10.0.0 prettytable-3.8.0 protobuf-4.23.4 qudida-0.0.4 sympy-1.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U insightface onnxruntime-gpu  numpy fastai pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (4.5.1)\n",
      "Collecting gdown\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Collecting moviepy\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ffmpeg\n",
      "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: insightface in /usr/local/lib/python3.9/dist-packages (0.7.3)\n",
      "Collecting natsort\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Collecting hdbscan\n",
      "  Downloading hdbscan-0.8.30.tar.gz (5.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting imutils\n",
      "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown) (4.64.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown) (3.7.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown) (1.14.0)\n",
      "Collecting decorator<5.0,>=4.0.2\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting proglog<=1.0.0\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from moviepy) (1.24.4)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.9/dist-packages (from moviepy) (2.19.3)\n",
      "Collecting imageio_ffmpeg>=0.2.0\n",
      "  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: easydict in /usr/local/lib/python3.9/dist-packages (from insightface) (1.10)\n",
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.9/dist-packages (from insightface) (1.3.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from insightface) (10.0.0)\n",
      "Requirement already satisfied: prettytable in /usr/local/lib/python3.9/dist-packages (from insightface) (3.8.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from insightface) (3.5.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from insightface) (1.1.1)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (from insightface) (0.29.30)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from insightface) (1.8.1)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from insightface) (0.19.3)\n",
      "Requirement already satisfied: onnx in /usr/local/lib/python3.9/dist-packages (from insightface) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.9/dist-packages (from hdbscan) (1.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->insightface) (3.1.0)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from albumentations->insightface) (5.3.1)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from albumentations->insightface) (0.0.4)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from albumentations->insightface) (4.8.0.74)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->insightface) (1.3.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image->insightface) (2.8.4)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image->insightface) (2022.5.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image->insightface) (21.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->insightface) (1.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->insightface) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->insightface) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->insightface) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->insightface) (4.34.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx->insightface) (4.3.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.9/dist-packages (from onnx->insightface) (4.23.4)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prettytable->insightface) (0.2.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Building wheels for collected packages: moviepy, ffmpeg, hdbscan, imutils\n",
      "  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110728 sha256=a6b433a768a800d01e319a751552507abc47522f21a69c16b59e19ffe1c7b87e\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/15/e4/4f790bec6acd51a00b67e8ee1394f0bc6e0135c315f8ff399a\n",
      "  Building wheel for ffmpeg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=9c2b18c34ad7b382f3f4a4136306f3347cf15fe7a95564622eb765d88853723c\n",
      "  Stored in directory: /root/.cache/pip/wheels/1d/57/24/4eff6a03a9ea0e647568e8a5a0546cdf957e3cf005372c0245\n",
      "  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hdbscan: filename=hdbscan-0.8.30-cp39-cp39-linux_x86_64.whl size=3584580 sha256=28649c23c17fd9bc3c28b03c4ff2cbba5d0dd31845e18c25f4a5cc7fd2329325\n",
      "  Stored in directory: /root/.cache/pip/wheels/99/9e/7f/0ce672c714a781cd1f254375189910f542fdee7518e00cce30\n",
      "  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25836 sha256=ed8c867529ed521f3d596fc9a65f87a618a9e9b719ca3de90ce683446ad82fca\n",
      "  Stored in directory: /root/.cache/pip/wheels/4b/a5/2d/4a070a801d3a3d93f033d3ee9728f470f514826e89952df3ea\n",
      "Successfully built moviepy ffmpeg hdbscan imutils\n",
      "Installing collected packages: imutils, ffmpeg, proglog, natsort, imageio_ffmpeg, decorator, moviepy, hdbscan, gdown\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "  Attempting uninstall: gdown\n",
      "    Found existing installation: gdown 4.5.1\n",
      "    Uninstalling gdown-4.5.1:\n",
      "      Successfully uninstalled gdown-4.5.1\n",
      "Successfully installed decorator-4.4.2 ffmpeg-1.4 gdown-4.7.1 hdbscan-0.8.30 imageio_ffmpeg-0.4.8 imutils-0.5.4 moviepy-1.0.3 natsort-8.4.0 proglog-0.1.10\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U gdown moviepy ffmpeg insightface natsort hdbscan imutils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import cv2\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip,AudioFileClip\n",
    "import glob\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "from insightface.data import get_image as ins_get_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define variables\n",
    "drive_file_id = '1KOKqWBDMQzwgQwvvbQm06-DThmxys9Xk'  # replace 'FILE_ID' with your file's ID\n",
    "video_output = 'my_video.mp4'\n",
    "frame_folder = '/notebooks/frame_folder'\n",
    "swapped_folder = '/notebooks/swapped'\n",
    "character_folder = '/notebooks/character'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(frame_folder)\n",
    "shutil.rmtree(swapped_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_path: /root/.insightface/models/buffalo_l\n",
      "Downloading /root/.insightface/models/buffalo_l.zip from https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281857/281857 [00:10<00:00, 25894.38KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "inswapper-shape: [1, 3, 128, 128]\n"
     ]
    }
   ],
   "source": [
    "assert insightface.__version__ >= '0.7'\n",
    "\n",
    "\n",
    "# Create the frame folder if it doesn't exist\n",
    "if not os.path.exists(frame_folder):\n",
    "    os.makedirs(frame_folder)\n",
    "# Create the frame folder if it doesn't exist\n",
    "if not os.path.exists(swapped_folder):\n",
    "    os.makedirs(swapped_folder)\n",
    "# Your face swapping script\n",
    "app = FaceAnalysis()\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "swapper = insightface.model_zoo.get_model('/notebooks/inswapper_128.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_first_face(image):\n",
    "    # If the image is a string (presumably a file path), read the image\n",
    "    if isinstance(image, str):\n",
    "        image = cv2.imread(image)\n",
    "\n",
    "    # Check if the image is a valid numpy array\n",
    "    if isinstance(image, np.ndarray):\n",
    "        source_faces = app.get(image)\n",
    "        source_faces = sorted(source_faces, key=lambda x: x.bbox[0])\n",
    "        if len(source_faces) == 0:\n",
    "            print(image)\n",
    "            assert False\n",
    "\n",
    "        return source_faces[0]\n",
    "    print(image)\n",
    "    assert False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://example.com/path_to_your_file\"  # replace with your file's URL\n",
    "response = requests.get(url)\n",
    "\n",
    "with open(video_output, 'wb') as f:  # replace with the path where you want to save the file\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download video from Google Drive\n",
    "url = f'https://drive.google.com/uc?id={drive_file_id}'\n",
    "gdown.download(url, video_output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete if swapped folder is not empty\n",
    "if  os.path.exists(character_folder):\n",
    "    shutil.rmtree(character_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "import datetime\n",
    "# Create the frame folder if it doesn't exist\n",
    "if not os.path.exists(character_folder):\n",
    "    os.makedirs(character_folder)\n",
    "if not os.path.exists(frame_folder):\n",
    "    os.makedirs(frame_folder)\n",
    "# Initialize the FaceAnalysis application\n",
    "\"\"\" app = FaceAnalysis(providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))  # Use GPU device 0 and input image size as (640, 640) \"\"\"\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_output)\n",
    "# Calculate frame rate (frames per second)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "face_index= 0\n",
    "# Initialize a list to store embeddings and face data for each detected face\n",
    "face_data = []\n",
    "count = 0\n",
    "# Loop through the video file frame by frame\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        # Calculate the time in minutes and seconds\n",
    "    time_in_milliseconds = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    frame_time = datetime.timedelta(milliseconds=time_in_milliseconds)\n",
    "    path = os.path.join(frame_folder, f\"{count}.jpg\")\n",
    "    cv2.imwrite(path, frame)  # save frame as JPEG file\n",
    "    # Use the FaceAnalysis application to detect faces in the frame\n",
    "    faces = app.get(frame)\n",
    "\n",
    "    # For each detected face, extract the embedding, bounding box, and face image, and add them to the list\n",
    "    for face in faces:\n",
    "        face_embedding = face.embedding\n",
    "        bbox = face.bbox.astype(int)\n",
    "        cropped_face = frame[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "        if cropped_face.size > 0:\n",
    "            face_data.append({'index':face_index,'label':'','frame':count,'time':frame_time,'face_embedding': face_embedding,'score':face.det_score,'normed_embedding': face.normed_embedding, 'bbox': bbox, 'image': cropped_face})\n",
    "        face_index += 1\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "# Save the face_data to disk\n",
    "with open('face_data.pkl', 'wb') as f:\n",
    "    pickle.dump(face_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_similar(face1, face2, threshold=0.5):\n",
    "    # Extract normalized embeddings\n",
    "    embedding1 = face1.normed_embedding\n",
    "    embedding2 = face2.normed_embedding\n",
    "\n",
    "    # Compute the dot product (cosine similarity, because embeddings are normalized)\n",
    "    similarity = np.dot(embedding1, embedding2)\n",
    "\n",
    "    # Return True if the similarity is above the threshold, False otherwise\n",
    "    return similarity > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "class FaceDataManager:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with open(self.file_path, 'rb') as f:\n",
    "            self.data = pickle.load(f)\n",
    "\n",
    "    def save_data(self):\n",
    "        with open(self.file_path, 'wb') as f:\n",
    "            pickle.dump(self.data, f)\n",
    "\n",
    "    def update_label(self, frame_number, face_image, new_label,save= True):\n",
    "        for f in self.data:\n",
    "            if f['frame'] == frame_number and np.array_equal(f['image'], face_image):\n",
    "                f['label'] = new_label\n",
    "        if save:\n",
    "            self.save_data()\n",
    "    def update_labels(self,old_label ,new_label):\n",
    "        for f in self.data:\n",
    "            if f['label'] == old_label:\n",
    "                f['label'] = new_label\n",
    "        self.save_data()\n",
    "    \n",
    "global face_data_manager\n",
    "face_data_manager = FaceDataManager('face_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Delete if swapped folder is not empty\n",
    "if  os.path.exists(character_folder):\n",
    "    shutil.rmtree(character_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import connected_components\n",
    "from scipy.sparse import csr_matrix\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from imutils import build_montages\n",
    "from sklearn.cluster import DBSCAN\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.manifold import MDS\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# calculate similarity matrix\n",
    "feats = []\n",
    "for face in face_data_manager.data:\n",
    "    feats.append(face[\"normed_embedding\"])\n",
    "feats = np.array(feats, dtype=np.float32)\n",
    "sims = np.dot(feats, feats.T)\n",
    "\"\"\" \n",
    "# define the similarity threshold\n",
    "threshold = 0.7  # set your value\n",
    "\n",
    "# create an adjacency matrix\n",
    "adjacency = sims > threshold\n",
    "\n",
    "# find connected components\n",
    "n_components, labels = connected_components(csgraph=csr_matrix(adjacency), directed=False)\n",
    "print(labels)\n",
    "# print the number of groups\n",
    "print(f'Total groups: {n_components}')\n",
    "uniqueLabels = np.unique(labels)\n",
    "print(uniqueLabels)\n",
    "for label in uniqueLabels:\n",
    "    # Skip the noise\n",
    "    if label == -1:\n",
    "        continue  \n",
    "\n",
    "    directory_path = os.path.join(character_folder, str(label))\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "\n",
    "    # Select samples associated with the current label\n",
    "    idxs = np.where(labels == label)[0]\n",
    "    faces = []\n",
    "    # loop over the sampled indexes\n",
    "    for i in idxs:\n",
    "        # Get the cropped face image from the 'image' key\n",
    "        face = face_data_manager.data[i][\"image\"]\n",
    "        frame = face_data_manager.data[i][\"frame\"]\n",
    "        face_data_manager.data[i]['label'] = str(label)\n",
    "        time_elapsed= face_data_manager.data[i]['time']\n",
    "        # Calculate minutes and seconds\n",
    "        minutes = time_elapsed.total_seconds() // 60\n",
    "        seconds = time_elapsed.total_seconds() % 60\n",
    "\n",
    "        # Format the time string as MM:SS\n",
    "        frame_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "        # Force resize the face to 96x96 and then add it to the\n",
    "        # faces montage list\n",
    "        face = cv2.resize(face, (150, 150))\n",
    "        cv2.putText(face,frame_time, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "        faces.append(face)\n",
    "\n",
    "        # Save face image\n",
    "        #image_path = os.path.join(directory_path, f\"{i}.jpg\")\n",
    "        #cv2.imwrite(image_path, face)\n",
    "\n",
    "    # Create a montage using 96x96 \"tiles\" with 5 rows and 5 columns\n",
    "    montage = build_montages(faces, (150, 150), (10, 8))[0]\n",
    "    # Save the output montage\n",
    "    title = \"Face ID #{}\".format(label)\n",
    "    title = \"Unknown Faces\" if label == -1 else title\n",
    "    cv2.imwrite(os.path.join(directory_path, title+'.jpg'), montage)\n",
    "\n",
    "    \n",
    "face_data_manager.save_data() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from imutils import build_montages\n",
    "from sklearn.cluster import DBSCAN\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "# Check if the directories exist\n",
    "if not os.path.exists(character_folder):\n",
    "    os.makedirs(character_folder)\n",
    "\n",
    "\n",
    "\"\"\" times = np.array([d['time'].total_seconds() for d in face_data_manager.data])\n",
    "times = times / np.max(times)\n",
    "scores \"\"\"\n",
    "embeddings = [d['normed_embedding'] for d in face_data_manager.data]\n",
    "embeddings = normalize(embeddings, norm='l2')\n",
    "\n",
    "clustering = DBSCAN(eps=0.5, min_samples=5,metric=\"cosine\")\n",
    "clustering.fit(embeddings)\n",
    "\n",
    "labels = np.unique(clustering.labels_)\n",
    "print(labels)\n",
    "for label in clustering.labels_:\n",
    "    # Skip the noise\n",
    "    if label == -1:\n",
    "        continue  \n",
    "\n",
    "    directory_path = os.path.join(character_folder, str(label))\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "\n",
    "    # Select samples associated with the current label\n",
    "    idxs = np.where(clustering.labels_ == label)[0]\n",
    "    faces = []\n",
    "    # loop over the sampled indexes\n",
    "    for i in idxs:\n",
    "        face_data_manager.data[i]['label'] = str(label)\n",
    "    idxs = np.random.choice(idxs, size=min(25, len(idxs)), replace=False)\n",
    "    for i in idxs:\n",
    "        # Get the time elapsed\n",
    "        time_elapsed = face_data_manager.data[i]['time']\n",
    "        minutes = time_elapsed.total_seconds() // 60\n",
    "        seconds = time_elapsed.total_seconds() % 60\n",
    "        # Calculate minutes and seconds\n",
    "        minutes = time_elapsed.total_seconds() // 60\n",
    "        seconds = time_elapsed.total_seconds() % 60\n",
    "        # Get the face from the data\n",
    "        face = face_data_manager.data[i][\"image\"]\n",
    "        # Format the time string as MM:SS\n",
    "        frame_time = \"{:02}:{:02}\".format(int(minutes), int(seconds))\n",
    "        # Force resize the face to 96x96 and then add it to the\n",
    "        # faces montage list\n",
    "        face = cv2.resize(face, (150, 150))\n",
    "        cv2.putText(face,frame_time, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "        faces.append(face)\n",
    "    montage = build_montages(faces, (150, 150), (5, 5))[0]\n",
    "    # Save the output montage\n",
    "    title = \"Face ID #{}\".format(label)\n",
    "    title = \"Unknown Faces\" if label == -1 else title\n",
    "    cv2.imwrite(os.path.join(directory_path, title+'.jpg'), montage)\n",
    "    \n",
    "face_data_manager.save_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from fastai.vision.all import *\n",
    "from pathlib import Path\n",
    "from PIL import Image as PilImage\n",
    "import shutil\n",
    "\n",
    "path = Path(character_folder)\n",
    "labels = [data[\"label\"] for data in face_data_manager.data if data[\"label\"].isnumeric()]\n",
    "\n",
    "def rename_folder(old_name, new_name):\n",
    "    if new_name.exists():  # If the target directory exists\n",
    "     \n",
    "        shutil.rmtree(old_name)\n",
    "    else:\n",
    "        old_name.rename(new_name)\n",
    "        \n",
    "def create_on_button_clicked_handler(label, name):\n",
    "    global face_data_manager\n",
    "    def on_button_clicked(b):\n",
    "        global face_data_manager\n",
    "        new_label = name.value\n",
    "        print(f'Character name confirmed: {new_label}')\n",
    "\n",
    "        face_data_manager.update_labels(label, new_label)\n",
    "\n",
    "        old_name = Path(Path(path) / label)\n",
    "        new_name = Path(Path(path) / new_label)\n",
    "\n",
    "        rename_folder(old_name, new_name)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        next(process)\n",
    "\n",
    "    return on_button_clicked\n",
    "def process_folders(labels, path):\n",
    "    global face_data_manager\n",
    "    for label in labels:\n",
    "        image_paths = list((path / label).glob('*.jpg'))\n",
    "        if not image_paths:\n",
    "            continue\n",
    "        print(f\"Current cluster: {label}\")\n",
    "\n",
    "        image_resolution = {}\n",
    "        for image_path in image_paths:\n",
    "            with PilImage.open(image_path) as img:\n",
    "                width, height = img.size\n",
    "                resolution = width * height  # resolution is defined as width * height\n",
    "                image_resolution[image_path] = resolution\n",
    "\n",
    "        sorted_image_paths = sorted(image_resolution, key=image_resolution.get, reverse=True)\n",
    "        name = widgets.Text(value=label, placeholder='Enter character name', description='Name:')\n",
    "        button = widgets.Button(description='Confirm')\n",
    "        display(name, button)\n",
    "        with open(sorted_image_paths[0], \"rb\") as file:\n",
    "            image = file.read()\n",
    "            img_widget = widgets.Image(value=image, format='png', width=1000, height=400)\n",
    "            display(img_widget)\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "        button.on_click(create_on_button_clicked_handler(label, name))\n",
    "  \n",
    "        yield\n",
    "\n",
    "process = process_folders(labels, path)\n",
    "next(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in face_data_manager.data:\n",
    "    if data[\"label\"].isnumeric():\n",
    "        print(data[\"index\"],\"is numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8994789e7f6d4dbf9d680724d51f9dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, description='Frame:', max=899, step=29)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab5e624fa234107a7259ffaa7c70562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from ipywidgets import HBox, VBox\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from fastai.vision.all import *\n",
    "from pathlib import Path\n",
    "from PIL import Image as PilImage\n",
    "import shutil\n",
    "\n",
    "path = Path(character_folder)\n",
    "def on_button_clicked_factory(face, frame_number, name, path, character_folder):\n",
    "    global face_data_manager\n",
    "    def on_button_clicked(b):\n",
    "        global face_data_manager\n",
    "        label = name.value\n",
    "        face_data_manager.update_label(frame_number, face['image'], label)\n",
    "        \"\"\"  old_name = Path(path / str(face['label']))\n",
    "            new_name = Path(path / label)\n",
    "            if new_name.exists():  \n",
    "                # Copy all .jpg files in the current folder to the target folder\n",
    "                for file in old_name.glob('*.jpg'):\n",
    "                    if new_name != old_name:\n",
    "                        shutil.copy(file, new_name / file.name)\n",
    "                    # Copy all .npy files (embeddings) in the current folder to the target folder\n",
    "                for file in old_name.glob('*.npy'):\n",
    "                    if new_name != old_name:\n",
    "                        shutil.copy(file, new_name / file.name) \"\"\"\n",
    "\n",
    "\n",
    "        \"\"\"  else:\n",
    "                if not os.path.exists(new_name):\n",
    "                    os.mkdir(new_name)\n",
    "                old_name.rename(new_name) \"\"\"\n",
    "        \"\"\"     process_frame(first_frame_with_label_0) \"\"\"\n",
    "        # At the start of your code, add the following line to get the first frame that has a label '0'\n",
    "    \"\"\"     first_frame_with_label_0 = min([f['frame'] for f in face_data_manager.data if f['label'] == '0' or f['label'] == ''], default=0)\n",
    "  \n",
    "        slider.value = first_frame_with_label_0 \"\"\"\n",
    "    return on_button_clicked\n",
    "\n",
    "def process_frame(frame_number):\n",
    "    global face_data_manager\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return  # end of video\n",
    "\n",
    "    frame_widget = convert_frame_to_widget(frame)\n",
    "\n",
    "    frame_output.clear_output()\n",
    "\n",
    "    with frame_output:\n",
    "        print(f\"Frame number: {frame_number}\")\n",
    "\n",
    "        faces = [p for p in face_data_manager.data if p[\"frame\"] == frame_number]\n",
    "        face_widgets = process_faces(faces,frame_number)\n",
    "\n",
    "        display(HBox([frame_widget] + face_widgets))\n",
    "\n",
    "\n",
    "def convert_frame_to_widget(frame):\n",
    "    frame_pil = PilImage.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    base_width = 500\n",
    "    w_percent = (base_width / float(frame_pil.size[0]))\n",
    "    h_size = int((float(frame_pil.size[1]) * float(w_percent)))\n",
    "    frame_pil = frame_pil.resize((base_width, h_size))\n",
    "\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    frame_pil.save(img_byte_arr, format='PNG')\n",
    "    return widgets.Image(value=img_byte_arr.getvalue(), format='png')\n",
    "\n",
    "\n",
    "def process_faces(faces, frame_number):\n",
    "    face_widgets = []\n",
    "    for face in faces:\n",
    "        print(f\"Time: {face['time']}\")\n",
    "        cropped_face_widget = convert_face_to_widget(face['image'])\n",
    "        name = widgets.Text(value=str(face['label']), placeholder='Enter character name', description='Name:')\n",
    "        button = widgets.Button(description='Confirm')\n",
    "\n",
    "        on_button_clicked = on_button_clicked_factory(face, frame_number, name, path, character_folder)\n",
    "        button.on_click(on_button_clicked)\n",
    "        face_box = VBox([cropped_face_widget, name, button])\n",
    "        face_widgets.append(face_box)\n",
    "    return face_widgets\n",
    "\n",
    "\n",
    "def convert_face_to_widget(face):\n",
    "    cropped_face_pil = PilImage.fromarray(face)\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    cropped_face_pil.save(img_byte_arr, format='PNG')\n",
    "    return widgets.Image(value=img_byte_arr.getvalue(), format='png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load video\n",
    "cap = cv2.VideoCapture(video_output)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Define an output widget for the frame display\n",
    "frame_output = widgets.Output()\n",
    "\n",
    "# At the start of your code, add the following line to get the first frame that has a label '0'\n",
    "first_frame_with_label_0 = min([f['frame'] for f in face_data_manager.data if f['label'] == '0' or f['label'] == ''], default=0)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "# Define a slider to navigate frames\n",
    "slider = widgets.IntSlider(min=0, max=total_frames, step=fps, description='Frame:')\n",
    "\n",
    "def on_slider_change(change):\n",
    "    process_frame(change['new'])\n",
    "\n",
    "slider.observe(on_slider_change, names='value')\n",
    "\n",
    "# Display the slider and frame_output widget\n",
    "display(slider, frame_output)\n",
    "\n",
    "# Process the first frame with label '0'\n",
    "process_frame(first_frame_with_label_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9969230769230769\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "\"\"\" data = [] \"\"\"\n",
    "\"\"\" for label in os.listdir(character_folder):\n",
    "    for filename in os.listdir(os.path.join(character_folder, label)):\n",
    "        if filename.endswith('.npy'):  # check if the file is an image\n",
    "            # read the image\n",
    "            img_path = os.path.join(character_folder, label, filename)\n",
    "            embedding = np.load(img_path)\n",
    "            data.append({'embedding': embedding, 'label': label})\n",
    "                \n",
    " \"\"\"\n",
    "# create a dataframe\n",
    "df = pd.DataFrame(face_data_manager.data)\n",
    "\n",
    "# Separate features and target\n",
    "X = np.array(df['normed_embedding'].to_list()) # Convert list of embeddings back to numpy array\n",
    "y = df['label'].values\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "# Normalize the embeddings\n",
    "normalizer = Normalizer(norm='l2')\n",
    "X = normalizer.transform(X)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2)\n",
    "\n",
    "# Define the model\n",
    "knn = KNeighborsClassifier(n_neighbors=5,metric=\"cosine\",weights=\"distance\")\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model\n",
    "accuracy = knn.score(X_val, y_val)\n",
    "print(f'Validation accuracy: {accuracy}')\n",
    "def classify_face(embedding):\n",
    "    normalizer = Normalizer(norm='l2')\n",
    "    embedding = normalizer.transform([embedding])\n",
    "    predicted_label = knn.predict(embedding)\n",
    "    predicted_label_str = le.inverse_transform(predicted_label)[0]\n",
    "\n",
    "    # Additional similarity check\n",
    "    similarity_threshold = 0.34\n",
    "    predicted_class_embeddings = X_train[y_train == predicted_label[0]]\n",
    "    sims_to_predicted_class = np.dot(predicted_class_embeddings, embedding[0])\n",
    "    if np.mean(sims_to_predicted_class) < similarity_threshold:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    return predicted_label_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.481767</td>\n",
       "      <td>1.975360</td>\n",
       "      <td>0.663580</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.747086</td>\n",
       "      <td>0.843763</td>\n",
       "      <td>0.984568</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.442451</td>\n",
       "      <td>0.175405</td>\n",
       "      <td>0.993827</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.284402</td>\n",
       "      <td>0.078458</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.198464</td>\n",
       "      <td>0.069320</td>\n",
       "      <td>0.993827</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.tabular.all import *\n",
    "import os\n",
    "import sys\n",
    "\n",
    "class SuppressPrints:\n",
    "    def __enter__(self):\n",
    "        self.original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self.original_stdout\n",
    "# Create a dataframe from your data\n",
    "df = pd.DataFrame(face_data_manager.data)\n",
    "\n",
    "# Separate features and target\n",
    "X = np.array(df['normed_embedding'].to_list())  # Convert list of embeddings back to numpy array\n",
    "y = df['label'].values\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Create a DataFrame for use with Fastai\n",
    "df_fastai = pd.DataFrame(X)\n",
    "df_fastai['label'] = y_encoded\n",
    "\n",
    "# Define categorical and continuous variables\n",
    "# We don't have any categorical variables in this case, so the list is empty\n",
    "cat_names = []\n",
    "# All the columns of embeddings are treated as continuous variables\n",
    "cont_names = list(df_fastai.columns[:-1])  # Exclude 'label' column\n",
    "\n",
    "# Define your splits for training and validation sets\n",
    "splits = TrainTestSplitter(test_size=0.2)(range_of(df_fastai))\n",
    "\n",
    "# Create a TabularDataLoaders\n",
    "dls = TabularDataLoaders.from_df(df_fastai, y_names=\"label\", y_block = CategoryBlock, \n",
    "                                 cat_names=cat_names, cont_names=cont_names, splits=splits, bs=64)\n",
    "\n",
    "# Define the model architecture\n",
    "# Here we use a simple feedforward neural network with two hidden layers of size 200 and 100.\n",
    "learn = tabular_learner(dls, layers=[200,100], metrics=accuracy)\n",
    "\n",
    "# Train the model\n",
    "learn.fit_one_cycle(5)\n",
    "\n",
    "def classify_face(embedding):\n",
    "    # Convert the embedding to DataFrame\n",
    "    df_new = pd.DataFrame([embedding], columns=cont_names)\n",
    "    # Use the trained model to make the prediction\n",
    "    with SuppressPrints():\n",
    "        pred_class, pred_idx, _ = learn.predict(df_new.iloc[0])\n",
    "    # Convert predicted index to integer\n",
    "    predicted_label = int(pred_idx)\n",
    "    predicted_label_str = le.inverse_transform([predicted_label])[0]\n",
    "\n",
    "    # Additional similarity check\n",
    "    similarity_threshold = 0.34\n",
    "    predicted_class_embeddings = X[y == int(predicted_label)]\n",
    "    sims_to_predicted_class = np.dot(predicted_class_embeddings, embedding)\n",
    "    if np.mean(sims_to_predicted_class) < similarity_threshold:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    return predicted_label_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(frame_folder):\n",
    "    os.makedirs(frame_folder)\n",
    "# Extract frames from video\n",
    "vidcap = cv2.VideoCapture(video_output)\n",
    "success, image = vidcap.read()\n",
    "count = 0\n",
    "target_imgs = []  # a list of file paths to images of the target faces\n",
    "while success:\n",
    "    path = os.path.join(frame_folder, f\"{count}.jpg\")\n",
    "    target_imgs.append(path)\n",
    "    cv2.imwrite(path, image)  # save frame as JPEG file\n",
    "    success, image = vidcap.read()\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete if swapped folder is not empty\n",
    "if  os.path.exists(swapped_folder):\n",
    "    shutil.rmtree(swapped_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the frame folder if it doesn't exist\n",
    "if not os.path.exists(swapped_folder):\n",
    "    os.makedirs(swapped_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "import natsort\n",
    "import cv2\n",
    "from collections import Counter, deque\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import build_montages\n",
    "\n",
    "swappings ={\n",
    "   'm':get_first_face('/notebooks/1629085462605.jpeg'),\n",
    "   'b':get_first_face('/notebooks/bcp.png'),\n",
    "   'd':get_first_face('/notebooks/DSCAAZZEA.png'),\n",
    "   'yd':get_first_face('/notebooks/2023-07-07 13.36.17.jpg'),\n",
    "   'l2':get_first_face('/notebooks/2023-07-03 22.46.08.jpg'),\n",
    "   'ylo':get_first_face('/notebooks/2023-07-07 13.36.21.jpg'),\n",
    "   'la':get_first_face('/notebooks/2023-07-03 22.47.10.jpg'),\n",
    "   'jo':get_first_face('/notebooks/jocp.png'),\n",
    "   'g':get_first_face('/notebooks/2023-07-08 14.11.53.jpg'),\n",
    "   'je':get_first_face('/notebooks/2023-07-03 22.47.24.jpg')\n",
    "}\n",
    "targets={\n",
    " 'f1': 'jo',\n",
    " 'm1': 'g',\n",
    " 'm2': 'm',\n",
    " 'f2': 'b',\n",
    " 'f': None,\n",
    " '': None,\n",
    " 'Unknown': None,\n",
    "}\n",
    "\n",
    "source_face = get_first_face('/notebooks/DSC06729.JPG')\n",
    "\n",
    "attribution = {}\n",
    "unused_keys = list(swappings.keys())\n",
    "for key in list(targets.keys()):\n",
    "    value = targets[key]\n",
    "    if value is not None:\n",
    "        unused_keys.remove(value)\n",
    "\n",
    "video = cv2.VideoCapture(video_output)\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "smoothing_window_size = 5\n",
    "face_classification_history = collections.defaultdict(lambda: deque(maxlen=int(fps)+1))\n",
    "\n",
    "start_frame = 725\n",
    "end_frame = None\n",
    "frame_count = -1\n",
    "DEBUG = False\n",
    "results = []  # List to hold face images for montage\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break  \n",
    "    frame_count += 1\n",
    "    if start_frame is not None and frame_count < start_frame:\n",
    "        continue\n",
    "    if end_frame is not None and frame_count > end_frame:\n",
    "        break\n",
    "\n",
    "    faces = app.get(frame)\n",
    "    \"\"\"     faces = sorted(faces, key=lambda x: x.bbox[0]) \"\"\"\n",
    "    res = frame.copy()\n",
    "\n",
    "    used_indices = set()  # Keep track of used indices in this frame\n",
    "    face_info = []  # List to store face info (index and position)\n",
    "    for face in faces:\n",
    "        index = classify_face(face.normed_embedding)\n",
    "        if index in used_indices:\n",
    "            continue\n",
    "        used_indices.add(index)  # Mark this index as used\n",
    "        \"\"\"         face_classification_history[index].append(index)\n",
    "                counter = Counter(face_classification_history[index])\n",
    "                most_common_index = counter.most_common(1)[0][0] \"\"\"\n",
    "        most_common_index = index\n",
    "        found = False\n",
    "        bbox = face.bbox.astype(int)\n",
    "        face_info.append((index,bbox))\n",
    "        # Store index and position for later use\n",
    "        \"\"\"         cropped_face = frame[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "                if cropped_face.size < 0:\n",
    "                    continue \"\"\"\n",
    "        \"\"\"         if face.det_score < 0.5:\n",
    "                    continue \"\"\"\n",
    "        if most_common_index in targets:\n",
    "            found = True\n",
    "            value = targets[most_common_index]\n",
    "            if value is not None:\n",
    "                res = swapper.get(res, face, swappings[value], paste_back=True)\n",
    "        if not found:\n",
    "            if most_common_index in attribution:\n",
    "                found = True\n",
    "                value = swappings[attribution[most_common_index]]\n",
    "                if value is not None:\n",
    "                    res = swapper.get(res, face, swappings[attribution[most_common_index]], paste_back=True)\n",
    "            else:\n",
    "                print(\"index not found :\" ,most_common_index)\n",
    "        if not found and index != \"Unknown\":\n",
    "            if len(unused_keys) == 0:  \n",
    "                unused_keys = list(swappings.keys())\n",
    "                for key in list(targets.keys()):\n",
    "                    if key in unused_keys:\n",
    "                        unused_keys.remove(key)\n",
    "            random_key = random.choice(unused_keys)\n",
    "            unused_keys.remove(random_key)\n",
    "            print(\"index \",most_common_index,\" attribute to \",random_key, \" frame \", frame_count)\n",
    "            attribution[most_common_index] = random_key\n",
    "            random_value = swappings[random_key]\n",
    "            res = swapper.get(res, face, random_value, paste_back=True)\n",
    "    cv2.imwrite(osp.join(swapped_folder, '{}.jpg'.format(frame_count)), res)\n",
    "    if DEBUG:\n",
    "        debug = res.copy()\n",
    "        for info in face_info:\n",
    "            index, bbox = info\n",
    "            new_bbox = bbox \n",
    "            cv2.putText(debug, str(index), (int(new_bbox[0]), int(new_bbox[1])), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "        debug =  cv2.resize(debug,  (400, 400), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        cv2.putText(debug,str(frame_count), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(debug,str(len(face_info)), (350, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "        results.append(debug)\n",
    "        # Every fps number of frames, create a montage and display it\n",
    "        if frame_count % int(fps) == 0:\n",
    "            montage = build_montages(results, (150, 150), (5, 5))[0]\n",
    "            # Calculate time elapsed in the video\n",
    "            time_elapsed = frame_count / fps  # time in seconds\n",
    "            minutes = int(time_elapsed // 60)\n",
    "            seconds = int(time_elapsed % 60)\n",
    "            print(f\"Current time in video: {minutes:02}:{seconds:02}\")\n",
    "            # Clear previous output and display the image\n",
    "            \"\"\"  clear_output(wait=True) \"\"\"\n",
    "            plt.figure(figsize=(400,400))\n",
    "            plt.imshow(cv2.cvtColor(montage, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "            results = []  # Clear the faces list\n",
    "    \n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_images = glob.glob(os.path.join(swapped_folder, '0*.jpg'))\n",
    "for file in processed_images:\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898\n",
      "720 1280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, image2, from '/notebooks/swapped/%01d.jpg':\n",
      "  Duration: 00:00:35.92, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 1280x720 [SAR 1:1 DAR 16:9], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x55a38a6c5380] deprecated pixel format used, make sure you did set range correctly\n",
      "[libx264 @ 0x55a38a1a8b80] using SAR=1/1\n",
      "[libx264 @ 0x55a38a1a8b80] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x55a38a1a8b80] profile High, level 3.1\n",
      "[libx264 @ 0x55a38a1a8b80] 264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to '/notebooks/output.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], q=-1--1, 29.97 fps, 30k tbn, 29.97 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  898 fps= 68 q=-1.0 Lsize=    6240kB time=00:00:29.86 bitrate=1711.9kbits/s speed=2.25x    \n",
      "video:6229kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.180648%\n",
      "[libx264 @ 0x55a38a1a8b80] frame I:20    Avg QP:19.68  size: 57896\n",
      "[libx264 @ 0x55a38a1a8b80] frame P:243   Avg QP:22.92  size: 13132\n",
      "[libx264 @ 0x55a38a1a8b80] frame B:635   Avg QP:25.73  size:  3195\n",
      "[libx264 @ 0x55a38a1a8b80] consecutive B-frames:  3.3%  4.2%  8.7% 83.7%\n",
      "[libx264 @ 0x55a38a1a8b80] mb I  I16..4: 17.6% 57.9% 24.5%\n",
      "[libx264 @ 0x55a38a1a8b80] mb P  I16..4:  5.6% 12.8%  1.3%  P16..4: 35.1% 10.3%  4.1%  0.0%  0.0%    skip:30.8%\n",
      "[libx264 @ 0x55a38a1a8b80] mb B  I16..4:  0.6%  1.0%  0.1%  B16..8: 30.7%  2.8%  0.4%  direct: 1.1%  skip:63.3%  L0:43.2% L1:53.2% BI: 3.6%\n",
      "[libx264 @ 0x55a38a1a8b80] 8x8 transform intra:62.3% inter:79.2%\n",
      "[libx264 @ 0x55a38a1a8b80] coded y,uvDC,uvAC intra: 42.6% 61.6% 18.1% inter: 6.7% 10.1% 0.2%\n",
      "[libx264 @ 0x55a38a1a8b80] i16 v,h,dc,p: 31% 25% 10% 34%\n",
      "[libx264 @ 0x55a38a1a8b80] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 28% 19% 22%  4%  5%  6%  5%  6%  5%\n",
      "[libx264 @ 0x55a38a1a8b80] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 30% 20% 10%  5%  8%  8%  7%  6%  5%\n",
      "[libx264 @ 0x55a38a1a8b80] i8c dc,h,v,p: 46% 22% 24%  8%\n",
      "[libx264 @ 0x55a38a1a8b80] Weighted P-Frames: Y:2.9% UV:2.5%\n",
      "[libx264 @ 0x55a38a1a8b80] ref P L0: 69.0% 12.4% 14.3%  4.3%  0.0%\n",
      "[libx264 @ 0x55a38a1a8b80] ref B L0: 91.3%  7.3%  1.4%\n",
      "[libx264 @ 0x55a38a1a8b80] ref B L1: 97.4%  2.6%\n",
      "[libx264 @ 0x55a38a1a8b80] kb/s:1702.89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "output_video = \"/notebooks/output.mp4\"\n",
    "video = cv2.VideoCapture(video_output)\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "video.release()\n",
    "\n",
    "# Get the processed images\n",
    "processed_images = glob.glob(os.path.join(swapped_folder, '*.jpg'))\n",
    "\n",
    "# Sort the processed images (this may be necessary depending on how your files are named)\n",
    "processed_images.sort()\n",
    "print(len(processed_images))\n",
    "# Initialize the video writer\n",
    "height, width, _ = cv2.imread(processed_images[0]).shape\n",
    "print(height, width)\n",
    "\n",
    "# Define the command\n",
    "command = f'ffmpeg -y -r {fps} -s {width}x{height} -i {swapped_folder}/%01d.jpg -vcodec libx264  -pix_fmt yuv420p {output_video}'\n",
    "\n",
    "# Execute the command\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'my_video.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    creation_time   : 2016-09-01T21:32:50.000000Z\n",
      "  Duration: 00:00:29.98, start: 0.000000, bitrate: 1538 kb/s\n",
      "    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 1408 kb/s, 30 fps, 29.97 tbr, 90k tbn, 59.94 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2016-09-01T21:32:50.000000Z\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 125 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2016-09-01T21:32:50.000000Z\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, adts, to '/notebooks/temp_audio.aac':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0(und): Audio: aac (LC), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2016-09-01T21:32:50.000000Z\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "size=     477kB time=00:00:29.97 bitrate= 130.2kbits/s speed=69.1x    \n",
      "video:0kB audio:468kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.888364%\n",
      "[aac @ 0x55cbc47d03c0] Qavg: 1675.288\n",
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/notebooks/output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:29.96, start: 0.000000, bitrate: 1706 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 1703 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "[aac @ 0x55d4dcd36780] Estimating duration from bitrate, this may be inaccurate\n",
      "Input #1, aac, from '/notebooks/temp_audio.aac':\n",
      "  Duration: 00:00:34.44, bitrate: 113 kb/s\n",
      "    Stream #1:0: Audio: aac (LC), 44100 Hz, stereo, fltp, 113 kb/s\n",
      "Output #0, mp4, to '/notebooks/output_with_audio.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 1703 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 30k tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "    Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 113 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #1:0 -> #0:1 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "frame=  898 fps=0.0 q=-1.0 Lsize=    6730kB time=00:00:29.97 bitrate=1839.1kbits/s speed=1.14e+03x    \n",
      "video:6229kB audio:477kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.359066%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='ffmpeg -y -i /notebooks/output.mp4 -i /notebooks/temp_audio.aac -c:v copy -c:a copy -map 0:v:0 -map 1:a:0 /notebooks/output_with_audio.mp4', returncode=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "temp_audio_file = '/notebooks/temp_audio.aac'\n",
    "\n",
    "# Remove temporary audio file if it exists\n",
    "if os.path.exists(temp_audio_file):\n",
    "    os.remove(temp_audio_file)\n",
    "\n",
    "# Remove output video with audio file if it exists\n",
    "output_with_audio_file = '/notebooks/output_with_audio.mp4'\n",
    "if os.path.exists(output_with_audio_file):\n",
    "    os.remove(output_with_audio_file)\n",
    "\n",
    "# Extract audio from original video and save it as a temporary audio file\n",
    "audio_extraction_command = f'ffmpeg -y -i {video_output} -vn -acodec aac -strict -2 {temp_audio_file}'\n",
    "subprocess.run(audio_extraction_command, shell=True)\n",
    "\n",
    "# Combine swapped video with original audio\n",
    "video_combination_command = f'ffmpeg -y -i {output_video} -i {temp_audio_file} -c:v copy -c:a copy -map 0:v:0 -map 1:a:0 {output_with_audio_file}'\n",
    "subprocess.run(video_combination_command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "\n",
    "# path to the video file\n",
    "video_path = output_with_audio_file\n",
    "\n",
    "# specify the start and end times in seconds\n",
    "# start time as (minutes, seconds)\n",
    "start_time_min_sec = (0, 0)  # 2 minutes 30 seconds\n",
    "start_time = start_time_min_sec[0]*60 + start_time_min_sec[1]\n",
    "\n",
    "# end time as (minutes, seconds)\n",
    "end_time_min_sec = (1, 40)  # 3 minutes 45 seconds\n",
    "end_time = end_time_min_sec[0]*60 + end_time_min_sec[1]\n",
    "\n",
    "# output file path\n",
    "output_path = \"/notebooks/split.mp4\"\n",
    "\n",
    "# extract subclip\n",
    "ffmpeg_extract_subclip(video_path, start_time, end_time, targetname=output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
