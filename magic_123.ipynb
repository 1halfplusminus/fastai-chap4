{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt update && !apt upgrade\n",
    "!apt install git wget libeigen3-dev -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/guochengqian/Magic123.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Magic123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install imageio_ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install  torch==2.0.0+cu118 torchvision==0.15.1+cu118 --index-url https://download.pytorch.org/whl/cu118 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd pretrained/zero123\n",
    "!wget https://huggingface.co/cvlab/zero123-weights/resolve/main/105000.ckpt\n",
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p pretrained/midas\n",
    "%cd pretrained/midas\n",
    "!wget https://github.com/isl-org/MiDaS/releases/download/v3_1/dpt_beit_large_512.pt\n",
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "workspace =\"werewolf_2\"\n",
    "DATA_DIR ='/notebooks/threestudio/load/images'\n",
    "image_path = f'{DATA_DIR}/rgba.png'\n",
    "image_path_without_rgba = f'{DATA_DIR}/{workspace}.png'\n",
    "save_path = f'./output/{workspace}'\n",
    "prompt = '''\n",
    "3D render of a cute litte werewolf ,fur,\n",
    "full body visible, model for painting in underwear\n",
    "'''\n",
    "# If the image contains non-front-facing objects, specifying the approximate elevation \n",
    "# and azimuth angle by setting data.default_elevation_deg and data.default_azimuth_deg can be helpful. \n",
    "# In threestudio, top is elevation +90 and bottom is elevation -90; left is azimuth -90 and right is azimuth +90.\n",
    "default_elevation_deg = 0\n",
    "default_azimuth_deg = 0\n",
    "GPU_IDX = 0\n",
    "init_token='werewolf'\n",
    "token_name = f'_{init_token}_'\n",
    "stable_version = '2.1'  #2.1 #2.0 #1.5\n",
    "MODEL_NAME = \"stabilityai/stable-diffusion-2-1-base\" # \"stabilityai/stable-diffusion-2-1-base\" # \"runwayml/stable-diffusion-v1-5\"\n",
    "DATA_DIR =image_path\n",
    "OUTPUT_DIR = save_path\n",
    "placeholder_token=token_name\n",
    "polar_angle=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preprocess_image.py --path {image_path_without_rgba}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DATA_DIR, IMAGE_NAME = os.path.split(image_path)\n",
    "FILENAME=IMAGE_NAME.split('.')[0]\n",
    "!cp  '{DATA_DIR}/rgba.png' '{DATA_DIR}/{workspace}_rgba.png'\n",
    "!cp  '{DATA_DIR}/depth.png' '{DATA_DIR}/{workspace}_depth.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "cmd = f\"\"\"\n",
    "textual-inversion/textual_inversion.py \\\n",
    "  --pretrained_model_name_or_path={MODEL_NAME} \\\n",
    "  --train_data_dir={DATA_DIR} \\\n",
    "  --learnable_property=\"object\" \\\n",
    "  --placeholder_token={init_token} \\\n",
    "  --initializer_token={init_token} \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=16 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --max_train_steps=3000 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --output_dir={OUTPUT_DIR} \\\n",
    "  --use_augmentations\n",
    "  \n",
    "\"\"\"\n",
    "%run {cmd}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guidance = f\"\"\"\n",
    "guidance/sd_utils.py \\\n",
    "  --sd_version {stable_version} \\\n",
    "  --text=\"A high-resolution DSLR image of <token>\" \\\n",
    "  --learned_embeds_path={OUTPUT_DIR} \\\n",
    "  --workspace={workspace}\n",
    "\"\"\"\n",
    "%run {guidance}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "RUN_ID = \"dmt\"\n",
    "RUN_ID2 = \"nerf\"\n",
    "DATA_DIR, IMAGE_NAME = os.path.split(image_path)\n",
    "FILENAME=IMAGE_NAME.split('.')[0]\n",
    "step1 = True # change this according to your needs\n",
    "step2 = True # change this according to your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmd= f\"\"\"\n",
    "main.py -O \\\n",
    "        --text \"A high-resolution DSLR image of <token>\" \\\n",
    "        --sd_version {stable_version} \\\n",
    "        --image {image_path} \\\n",
    "        --learned_embeds_path {OUTPUT_DIR}/learned_embeds.bin \\\n",
    "        --workspace out/magic123-{RUN_ID}-coarse/$dataset/magic123_${FILENAME}_${RUN_ID}_coarse \\\n",
    "        --optim adam \\\n",
    "        --iters 5000 \\\n",
    "        --guidance SD zero123 \\\n",
    "        --lambda_guidance 1.0 40 \\\n",
    "        --guidance_scale 100 5 \\\n",
    "        --latent_iter_ratio 0 \\\n",
    "        --normal_iter_ratio 0.2 \\\n",
    "        --t_range 0.2 0.6 \\\n",
    "        --bg_radius -1 \\\n",
    "        --default_polar {polar_angle} \\\n",
    "        --save_mesh \n",
    "\"\"\"\n",
    "if step1:\n",
    "    %run {cmd}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if step2:\n",
    "    cmd2 = f\"\"\"\n",
    "    main.py -O \\\n",
    "        --text \"A high-resolution DSLR image of <token>\" \\\n",
    "        --sd_version {stable_version} \\\n",
    "        --image {image_path} \\\n",
    "        --learned_embeds_path {OUTPUT_DIR}/learned_embeds.bin  \\\n",
    "        --workspace out/magic123-{RUN_ID}-{RUN_ID2}/$dataset/magic123_${FILENAME}_${RUN_ID}_${RUN_ID2} \\\n",
    "        --dmtet --init_ckpt out/magic123-{RUN_ID}-coarse/$dataset/magic123_${FILENAME}_${RUN_ID}_coarse/checkpoints/magic123_${FILENAME}_${RUN_ID}_coarse.pth \\\n",
    "        --iters 5000 \\\n",
    "        --optim adam \\\n",
    "        --latent_iter_ratio 0 \\\n",
    "        --guidance SD zero123 \\\n",
    "        --lambda_guidance 1e-3 0.01 \\\n",
    "        --guidance_scale 100 5 \\\n",
    "        --rm_edge \\\n",
    "        --bg_radius -1 \\\n",
    "        --default_polar {polar_angle} \\\n",
    "        --save_mesh\n",
    "    \"\"\"\n",
    "    %run {cmd2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID2=\"coarse\"\n",
    "path = f\"\"\"/notebooks/Magic123/out/magic123-{RUN_ID}-{RUN_ID2}/$dataset/magic123_${FILENAME}_${RUN_ID}_${RUN_ID2}\"\"\"\n",
    "%cd {path}\n",
    "!zip {workspace}.zip -r mesh\n",
    "%cd ../\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreamfusion",
   "language": "python",
   "name": "dreamfusion"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
