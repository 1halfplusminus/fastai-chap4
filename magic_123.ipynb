{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt update && !apt upgrade\n",
    "!apt install git wget libeigen3-dev -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/guochengqian/Magic123.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Magic123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd pretrained/zero123\n",
    "!wget https://huggingface.co/cvlab/zero123-weights/resolve/main/105000.ckpt\n",
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p pretrained/midas\n",
    "%cd pretrained/midas\n",
    "!wget https://github.com/isl-org/MiDaS/releases/download/v3_1/dpt_beit_large_512.pt\n",
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "workspace =\"scorp_side\"\n",
    "image_path = f'/notebooks/threestudio/load/images/{workspace}_rgba.png'\n",
    "image_path_without_rgba = image_path.replace('_rgba', '')\n",
    "save_path = f'./output/{workspace}'\n",
    "prompt = '''\n",
    "'''\n",
    "# If the image contains non-front-facing objects, specifying the approximate elevation \n",
    "# and azimuth angle by setting data.default_elevation_deg and data.default_azimuth_deg can be helpful. \n",
    "# In threestudio, top is elevation +90 and bottom is elevation -90; left is azimuth -90 and right is azimuth +90.\n",
    "default_elevation_deg = 0\n",
    "default_azimuth_deg = 0\n",
    "GPU_IDX = 0\n",
    "init_token='scorpside'\n",
    "token_name = f'_{init_token}_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preprocess_image.py --path {image_path_without_rgba}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
    "DATA_DIR =image_path\n",
    "OUTPUT_DIR = save_path\n",
    "placeholder_token=token_name\n",
    "cmd = f\"\"\"\n",
    "textual-inversion/textual_inversion.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir={DATA_DIR} \\\n",
    "  --learnable_property=\"object\" \\\n",
    "  --placeholder_token={placeholder_token} \\\n",
    "  --initializer_token={init_token} \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=16 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --max_train_steps=3000 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --output_dir={OUTPUT_DIR} \\\n",
    "  --use_augmentations\n",
    "  \n",
    "\"\"\"\n",
    "%run {cmd}\n",
    "  \n",
    "%run guidance/sd_utils.py \\\n",
    "  --text=\"A high-resolution DSLR image of <token>\" \\\n",
    "  --learned_embeds_path={OUTPUT_DIR} \\\n",
    "  --workspace={OUTPUT_DIR}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "RUN_ID = \"jobname_for_the_first_stage\"\n",
    "RUN_ID2 = \"jobname_for_the_second_stage\"\n",
    "DATA_DIR, IMAGE_NAME = os.path.split(image_path)\n",
    "step1 = True # change this according to your needs\n",
    "step2 = True # change this according to your needs\n",
    "if step1:\n",
    "    !CUDA_VISIBLE_DEVICES=0 python main.py -O \\\n",
    "        --text \"A high-resolution DSLR image of <token>\" \\\n",
    "        --sd_version 1.5 \\\n",
    "        --image {image_path} \\\n",
    "        --learned_embeds_path {OUTPUT_DIR}/learned_embeds.bin \\\n",
    "        --workspace out/magic123-{RUN_ID}-coarse/$dataset/magic123_${FILENAME}_${RUN_ID}_coarse \\\n",
    "        --optim adam \\\n",
    "        --iters 5000 \\\n",
    "        --guidance SD zero123 \\\n",
    "        --lambda_guidance 1.0 40 \\\n",
    "        --guidance_scale 100 5 \\\n",
    "        --latent_iter_ratio 0 \\\n",
    "        --normal_iter_ratio 0.2 \\\n",
    "        --t_range 0.2 0.6 \\\n",
    "        --bg_radius -1 \\\n",
    "        --save_mesh \n",
    "\n",
    "if step2:\n",
    "    !CUDA_VISIBLE_DEVICES=0 python main.py -O \\\n",
    "        --text \"A high-resolution DSLR image of <token>\" \\\n",
    "        --sd_version 1.5 \\\n",
    "        --image {image_path} \\\n",
    "        --learned_embeds_path {OUTPUT_DIR}/learned_embeds.bin  \\\n",
    "        --workspace out/magic123-{RUN_ID}-{RUN_ID2}/$dataset/magic123_${FILENAME}_${RUN_ID}_${RUN_ID2} \\\n",
    "        --dmtet --init_ckpt out/magic123-{RUN_ID}-coarse/$dataset/magic123_${FILENAME}_${RUN_ID}_coarse/checkpoints/magic123_${FILENAME}_${RUN_ID}_coarse.pth \\\n",
    "        --iters 5000 \\\n",
    "        --optim adam \\\n",
    "        --latent_iter_ratio 0 \\\n",
    "        --guidance SD zero123 \\\n",
    "        --lambda_guidance 1e-3 0.01 \\\n",
    "        --guidance_scale 100 5 \\\n",
    "        --rm_edge \\\n",
    "        --bg_radius -1 \\\n",
    "        --save_mesh "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magic_123",
   "language": "python",
   "name": "magic_123"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
