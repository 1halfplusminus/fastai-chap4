{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/threestudio-project/threestudio.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get update\n",
    "!sudo apt-get install mesa-common-dev libegl1-mesa-dev -y\n",
    "!sudo apt-get install ninja-build  -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /notebooks/threestudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" %pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 --extra-index-url https://download.pytorch.org/whl/cu113 \"\"\"\n",
    "%pip install ninja\n",
    "%pip install  torch==2.0.0+cu118 torchvision==0.15.1+cu118 --index-url https://download.pytorch.org/whl/cu118 \n",
    "%pip install mediapipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\bdone\n",
      "\u001b[?25h  Created wheel for tinycudann: filename=tinycudann-1.7-cp310-cp310-linux_x86_64.whl size=24285556 sha256=edac2d4ff1f59d565d4a76e26c9fe593a2a03c65c7cce3ce8d14d28932b41d94\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8b7ihoyd/wheels/32/d8/5e/dc94eca0794af9e09a6d97f19cf15dfe9bbbc4d56ae4db4aa2\n",
      "  Building wheel for nvdiffrast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvdiffrast: filename=nvdiffrast-0.3.1-py3-none-any.whl size=137847 sha256=e3c86cfcf857be1992facf694b546f732441502636d195b4df16a910e1a59146\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8b7ihoyd/wheels/24/2b/98/f611ce0d4062793b78daf724e6b47ee800c9a2d3e1ff4b06fa\n",
      "  Building wheel for pysdf (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pysdf: filename=pysdf-0.1.9-cp310-cp310-linux_x86_64.whl size=162147 sha256=574912c61b1d79f547a8b8fd43c042734c5ca819b8321c0482ee1899b75a7d0e\n",
      "  Stored in directory: /root/.cache/pip/wheels/3a/ea/2e/fcf66dcef78ab3664f967b3c1da5b928b15a13999ac15c11a3\n",
      "  Building wheel for envlight (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for envlight: filename=envlight-0.1.0-py3-none-any.whl size=39752 sha256=f2c21fab4689316d26d4788d3a5196333aad0cd7315ce9f19841d5406be463a4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8b7ihoyd/wheels/c8/03/70/2579ccfef7bef64158f69ebc5e12de9b560ef319dfe948e55a\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369500 sha256=2462ce84eb6030a10d10eb3fb841155f06c56df402e5f5ebd9e350a21be90fc7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8b7ihoyd/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=cb4564ddcdee8cdfe15109c80c8a81b368e7186af3e9514e05afc7c52dfeca2d\n",
      "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8792 sha256=7d4ac3fe2b8f58ce4fb2c395c6ae46b6093a0d3609c932c87b6caf65643a5376\n",
      "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
      "  Building wheel for pycollada (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycollada: filename=pycollada-0.7.2-py3-none-any.whl size=127020 sha256=b01e1c3cd5e52c91cfb2997676a063cd1bb0a1b4e8fbbee84b80e437631c9bc8\n",
      "  Stored in directory: /root/.cache/pip/wheels/d5/ba/33/1e99a7e7defd1d77f0210e7a39ff58de2a2d8d4c22466bb2da\n",
      "Successfully built antlr4-python3-runtime nerfacc tinycudann nvdiffrast pysdf envlight clip ffmpy pathtools pycollada\n",
      "Installing collected packages: xatlas, tokenizers, tinycudann, sentencepiece, safetensors, python-editor, pysdf, pydub, pathtools, ffmpy, bitsandbytes, appdirs, antlr4-python3-runtime, xxhash, werkzeug, websockets, tzdata, typing-extensions, tensorboard-data-server, svg.path, smmap, setproctitle, sentry-sdk, semantic-version, rtree, regex, readchar, PyYAML, python-multipart, pyjwt, pyasn1, orjson, ordered-set, oauthlib, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, multidict, mdurl, markdown, lxml, lazy_loader, itsdangerous, imageio-ffmpeg, h11, grpcio, ftfy, fsspec, frozenlist, einops, docker-pycreds, colorlog, click, chardet, cachetools, blessed, async-timeout, aiofiles, yarl, uvicorn, typeguard, trimesh, tifffile, starlette, shapely, scipy, rsa, requests-oauthlib, PyWavelets, pydantic, pycollada, pyasn1-modules, pandas, opencv-python, omegaconf, oldest-supported-numpy, nvidia-cusolver-cu11, nvidia-cudnn-cu11, nvdiffrast, markdown-it-py, mapbox-earcut, lightning-utilities, inquirer, imageio, huggingface_hub, httpcore, gitdb, deepdiff, dateutils, croniter, arrow, aiosignal, transformers, starsessions, scikit-image, rich, PyMCubes, libigl, jaxtyping, httpx, google-auth, GitPython, fastapi, envlight, embreex, diffusers, altair, aiohttp, wandb, lightning-cloud, gradio-client, google-auth-oauthlib, tensorboard, gradio, torch, torchvision, torchmetrics, timm, pytorch-lightning, xformers, taming-transformers-rom1504, nerfacc, lightning, kornia, controlnet_aux, clip, accelerate\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.1\n",
      "    Uninstalling numpy-1.24.1:\n",
      "      Successfully uninstalled numpy-1.24.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.0+cu118\n",
      "    Uninstalling torch-2.0.0+cu118:\n",
      "      Successfully uninstalled torch-2.0.0+cu118\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.15.1+cu118\n",
      "    Uninstalling torchvision-0.15.1+cu118:\n",
      "      Successfully uninstalled torchvision-0.15.1+cu118\n",
      "Successfully installed GitPython-3.1.32 PyMCubes-0.1.4 PyWavelets-1.4.1 PyYAML-6.0.1 accelerate-0.22.0 aiofiles-23.2.1 aiohttp-3.8.5 aiosignal-1.3.1 altair-5.0.1 antlr4-python3-runtime-4.9.3 appdirs-1.4.4 arrow-1.2.3 async-timeout-4.0.3 bitsandbytes-0.38.1 blessed-1.20.0 cachetools-5.3.1 chardet-5.2.0 click-8.1.7 clip-1.0 colorlog-6.7.0 controlnet_aux-0.0.6 croniter-1.3.15 dateutils-0.6.12 deepdiff-6.3.1 diffusers-0.20.1 docker-pycreds-0.4.0 einops-0.6.1 embreex-2.17.7.post2 envlight-0.1.0 fastapi-0.88.0 ffmpy-0.3.1 frozenlist-1.4.0 fsspec-2023.6.0 ftfy-6.1.1 gitdb-4.0.10 google-auth-2.22.0 google-auth-oauthlib-1.0.0 gradio-3.41.2 gradio-client-0.5.0 grpcio-1.57.0 h11-0.14.0 httpcore-0.17.3 httpx-0.24.1 huggingface_hub-0.16.4 imageio-2.31.2 imageio-ffmpeg-0.4.8 inquirer-3.1.3 itsdangerous-2.1.2 jaxtyping-0.2.21 kornia-0.7.0 lazy_loader-0.3 libigl-2.4.1 lightning-2.0.0 lightning-cloud-0.5.37 lightning-utilities-0.9.0 lxml-4.9.3 mapbox-earcut-1.0.1 markdown-3.4.4 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.0.4 nerfacc-0.5.2 numpy-1.21.6 nvdiffrast-0.3.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 oauthlib-3.2.2 oldest-supported-numpy-2023.8.3 omegaconf-2.3.0 opencv-python-4.8.0.76 ordered-set-4.1.0 orjson-3.9.5 pandas-2.0.3 pathtools-0.1.2 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycollada-0.7.2 pydantic-1.10.12 pydub-0.25.1 pyjwt-2.8.0 pysdf-0.1.9 python-editor-1.0.4 python-multipart-0.0.6 pytorch-lightning-2.0.7 readchar-4.0.5 regex-2023.8.8 requests-oauthlib-1.3.1 rich-13.5.2 rsa-4.9 rtree-1.0.1 safetensors-0.3.3 scikit-image-0.21.0 scipy-1.11.2 semantic-version-2.10.0 sentencepiece-0.1.99 sentry-sdk-1.29.2 setproctitle-1.3.2 shapely-2.0.1 smmap-5.0.0 starlette-0.22.0 starsessions-1.3.0 svg.path-6.3 taming-transformers-rom1504-0.0.6 tensorboard-2.14.0 tensorboard-data-server-0.7.1 tifffile-2023.8.25 timm-0.9.5 tinycudann-1.7 tokenizers-0.13.3 torch-2.0.1 torchmetrics-1.1.0 torchvision-0.15.2 transformers-4.28.1 trimesh-3.23.5 typeguard-4.1.3 typing-extensions-4.7.1 tzdata-2023.3 uvicorn-0.23.2 wandb-0.15.8 websockets-11.0.3 werkzeug-2.3.7 xatlas-0.0.8 xformers-0.0.21 xxhash-3.3.0 yarl-1.9.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install  -r requirements.txt   # --force-reinstall  --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lightning==2.0.0 omegaconf==2.3.0 jaxtyping typeguard diffusers transformers accelerate opencv-python tensorboard matplotlib imageio imageio[ffmpeg] trimesh bitsandbytes sentencepiece safetensors huggingface_hub libigl xatlas \n",
    "%pip install open3d plotly # mesh visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/KAIR-BAIR/nerfacc.git@v0.5.2\n",
    "%pip install git+https://github.com/NVlabs/nvdiffrast.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir load/zero123\n",
    "%cd load/zero123\n",
    "!wget https://zero123.cs.columbia.edu/assets/zero123-xl.ckpt\n",
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "# Set environment variable\n",
    "name = \"dragon3\"\n",
    "prompt = \"an 3D render of a cartoon skeleton of a chibi dragon, detailed, 8k\"\n",
    "last=\"last-v3\"\n",
    "%cd /notebooks/threestudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run launch.py --config configs/magic123-coarse-sd.yaml --train --gpu 0 data.image_path=load/images/hamburger_rgba.png system.prompt_processor.prompt=\"a delicious hamburger\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" data.default_elevation_deg=0\n",
    "data.default_azimuth_deg=90\n",
    "data.default_camera_distance=1\n",
    "system.freq.guidance_eval=0 \"\"\"\n",
    "cmd = f''' --train --gpu 0\n",
    "--config configs/zero123_64.yaml\n",
    "data.image_path=\"load/images/{name}_rgba.png\"\n",
    "name=\"{name}\"\n",
    "tag=Phase1\n",
    "system.loggers.wandb.enable=false\n",
    "use_timestamp=False\n",
    "data.default_azimuth_deg=0\n",
    "data.random_camera.batch_size=14\n",
    "system.loss.lambda_depth=0.05\n",
    "system.loss.lambda_depth_rel=\"[0, 0, 0.05, 100]\"\n",
    "system.loss.lambda_normal=\"[0, 0, 0.05, 100]\"\n",
    "system.geometry.density_blob_scale=8.\n",
    "system.freq.guidance_eval=37\n",
    "system.guidance.cond_elevation_deg=0\n",
    "'''\n",
    "\n",
    "%run launch.py {cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1.5 - 512 refine\n",
    "#system.loggers.wandb.project=\"zero123\" system.loggers.wandb.name=${NAME}_Phase1p5\n",
    "\n",
    "cmd = f'''--config configs/zero123-geometry.yaml --train --gpu 0 \n",
    "data.image_path=./load/images/{name}_rgba.png \n",
    "system.geometry_convert_from=./outputs/{name}/Phase1/ckpts/{last}.ckpt \n",
    "use_timestamp=False name={name} tag=Phase1p5'''\n",
    "\n",
    "%run launch.py {cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2 - dreamfusion\n",
    "#data.random_camera.batch_size=2 trainer.accumulate_grad_batches=4 system.freq.guidance_eval=0\n",
    "# system.freq.guidance_eval=0 system.loggers.wandb.enable=false system.loggers.wandb.project=\"zero123\" system.loggers.wandb.name=${NAME}_Phase2\n",
    "tag=\"Phase1p5\"\n",
    "last=\"last\"\n",
    "cmd = f'''--config configs/experimental/imagecondition_zero123nerf.yaml \n",
    "--train --gpu 0 data.image_path=./load/images/{name}_rgba.png\n",
    "system.prompt_processor.prompt=\"{prompt}\" \n",
    "system.weights=\"./outputs/{name}/{tag}/ckpts/{last}.ckpt\" \n",
    "system.freq.guidance_eval=23\n",
    "name={name} tag=Phase2 system.loggers.wandb.enable=false  use_timestamp=False'''\n",
    "\n",
    "%run launch.py {cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Phase 2 - dreamfusion\n",
    "cmd = f'''--config configs/experimental/my_imagecondition_zero123nerf_refine.yaml \n",
    "--train --gpu 0  system.prompt_processor.prompt=\"{prompt}\" \n",
    "system.geometry_convert_from=\"./outputs/{name}/{phase}/ckpts/{last}.ckpt\" \n",
    "name={name} \n",
    "tag=Phase2_refine system.loggers.wandb.enable=false \n",
    "use_timestamp=False\n",
    "data.image_path=./load/images/{name}_rgba.png\n",
    "'''\n",
    "\n",
    "%run launch.py {cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag=\"Phase1p5\"\n",
    "last=\"last\"\n",
    "cmd=f'''--config \"outputs/{name}/{tag}/configs/parsed.yaml\" \n",
    "--export --gpu 0 resume=\"outputs/{name}/{tag}/ckpts/{last}.ckpt\" \n",
    "system.exporter.context_type=cuda  system.exporter_type=mesh-exporter'''\n",
    "%run launch.py {cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT MESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses DeepFloyd IF, requires ~15GB VRAM\n",
    "cmd= f'''\n",
    "--config configs/textmesh-if.yaml --train --gpu 0 tag=DRAGON system.prompt_processor.prompt=\"{prompt}\"\n",
    "system.prompt_processor_type=\"stable-diffusion-prompt-processor\"\n",
    "system.guidance_type=\"stable-diffusion-guidance\"\n",
    "system.guidance.pretrained_model_name_or_path=\"stabilityai/stable-diffusion-2-1\"\n",
    "system.prompt_processor.pretrained_model_name_or_path=\"stabilityai/stable-diffusion-2-1\"\n",
    "'''\n",
    "%run launch.py {cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag=\"DRAGON@20230726-085910\"\n",
    "name=\"textmesh-if\"\n",
    "cmd=f'--config \"outputs/{name}/{tag}/configs/parsed.yaml\" --export --gpu 0 resume=\"outputs/{name}/{tag}/ckpts/last.ckpt\" system.exporter.context_type=cuda  system.exporter_type=mesh-exporter'\n",
    "%run launch.py {cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONTROL 4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f'''--config configs/control4d-static.yaml --train --gpu 0 \n",
    "data.dataroot=\"YOUR_DATAROOT/twindom\" \n",
    "system.prompt_processor.prompt=\"{prompt}\" \n",
    "name={name} \n",
    "tag=Phase1 \n",
    "system.loggers.wandb.enable=false \n",
    "use_timestamp=False'''\n",
    "\n",
    "%run launch.py {cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "/notebooks/threestudio\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "workspace =\"scorp_side\"\n",
    "image_path = f'/notebooks/threestudio/load/images/{workspace}_rgba.png'\n",
    "image_path_without_rgba = image_path.replace('_rgba', '')\n",
    "prompt = '''\n",
    "high quality amazing detailed art of \n",
    "an 3D stylized battle (scorpions robot)\n",
    "'''\n",
    "# If the image contains non-front-facing objects, specifying the approximate elevation \n",
    "# and azimuth angle by setting data.default_elevation_deg and data.default_azimuth_deg can be helpful. \n",
    "# In threestudio, top is elevation +90 and bottom is elevation -90; left is azimuth -90 and right is azimuth +90.\n",
    "default_elevation_deg = 0\n",
    "default_azimuth_deg = -85\n",
    "%cd /notebooks/threestudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python==4.8.0.76\n",
      "  Obtaining dependency information for opencv-python==4.8.0.76 from https://files.pythonhosted.org/packages/f5/d0/2e455d894ec0d6527e662ad55e70c04f421ad83a6fd0a54c3dd73c411282/opencv_python-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached opencv_python-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting numpy==1.23\n",
      "  Downloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached opencv_python-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
      "Installing collected packages: numpy, opencv-python\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.6\n",
      "    Uninstalling numpy-1.21.6:\n",
      "      Successfully uninstalled numpy-1.21.6\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.8.0.76\n",
      "    Uninstalling opencv-python-4.8.0.76:\n",
      "      Successfully uninstalled opencv-python-4.8.0.76\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "oldest-supported-numpy 2023.8.3 requires numpy==1.21.6; python_version == \"3.10\" and platform_machine != \"loongarch64\", but you have numpy 1.23.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.23.0 opencv-python-4.8.0.76\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python==4.8.0.76 numpy==1.23 --force-reinstall --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "\u001b[32m[INFO] Loading Stable Diffusion ...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013538837432861328,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading pipeline components...",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2368f4669e5546fd8014e797dda6f012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] Loaded Stable Diffusion!\u001b[0m\n",
      "\u001b[32m[INFO] Loading Zero123 ...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011547565460205078,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading pipeline components...",
       "rate": null,
       "total": 6,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8386a9efafd4421d87f53e1101598503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 47.54 GiB total capacity; 7.36 GiB already allocated; 11.12 MiB free; 7.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/notebooks/threestudio/launch.py:237\u001b[0m\n\u001b[1;32m    235\u001b[0m         main(args, extras)\n\u001b[1;32m    236\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     main(args, extras)\n",
      "File \u001b[0;32m/notebooks/threestudio/launch.py:105\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args, extras)\u001b[0m\n\u001b[1;32m    102\u001b[0m pl\u001b[39m.\u001b[39mseed_everything(cfg\u001b[39m.\u001b[39mseed \u001b[39m+\u001b[39m get_rank(), workers\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    104\u001b[0m dm \u001b[39m=\u001b[39m threestudio\u001b[39m.\u001b[39mfind(cfg\u001b[39m.\u001b[39mdata_type)(cfg\u001b[39m.\u001b[39mdata)\n\u001b[0;32m--> 105\u001b[0m system: BaseSystem \u001b[39m=\u001b[39m threestudio\u001b[39m.\u001b[39;49mfind(cfg\u001b[39m.\u001b[39;49msystem_type)(\n\u001b[1;32m    106\u001b[0m     cfg\u001b[39m.\u001b[39;49msystem, resumed\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mresume \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    107\u001b[0m )\n\u001b[1;32m    108\u001b[0m system\u001b[39m.\u001b[39mset_save_dir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(cfg\u001b[39m.\u001b[39mtrial_dir, \u001b[39m\"\u001b[39m\u001b[39msave\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    110\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mgradio:\n",
      "File \u001b[0;32m/notebooks/threestudio/threestudio/systems/base.py:45\u001b[0m, in \u001b[0;36mBaseSystem.__init__\u001b[0;34m(self, cfg, resumed)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mloggers\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m cfg:\n\u001b[1;32m     43\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_loggers(cfg\u001b[39m.\u001b[39mloggers)\n\u001b[0;32m---> 45\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfigure()\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mweights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_weights(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mweights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mweights_ignore_modules)\n",
      "File \u001b[0;32m/notebooks/threestudio/threestudio/systems/magic123.py:26\u001b[0m, in \u001b[0;36mMagic123.configure\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mconfigure()\n\u001b[1;32m     25\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mguidance \u001b[39m=\u001b[39m threestudio\u001b[39m.\u001b[39mfind(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mguidance_type)(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mguidance)\n\u001b[0;32m---> 26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mguidance_3d \u001b[39m=\u001b[39m threestudio\u001b[39m.\u001b[39;49mfind(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcfg\u001b[39m.\u001b[39;49mguidance_3d_type)(\n\u001b[1;32m     27\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcfg\u001b[39m.\u001b[39;49mguidance_3d\n\u001b[1;32m     28\u001b[0m )\n",
      "File \u001b[0;32m/notebooks/threestudio/threestudio/utils/base.py:102\u001b[0m, in \u001b[0;36mBaseModule.__init__\u001b[0;34m(self, cfg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg \u001b[39m=\u001b[39m parse_structured(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mConfig, cfg)\n\u001b[1;32m    101\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m get_device()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfigure(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    103\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mweights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[39m# format: path/to/weights:module_name\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     weights_path, module_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mweights\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/notebooks/threestudio/threestudio/models/guidance/zero123_unified_guidance.py:99\u001b[0m, in \u001b[0;36mZero123UnifiedGuidance.configure\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mextern/\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m pipe_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m     91\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msafety_checker\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrequires_safety_checker\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     93\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mvariant\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mfp16\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mhalf_precision_weights \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     94\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtorch_dtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights_dtype,\n\u001b[1;32m     95\u001b[0m }\n\u001b[1;32m     96\u001b[0m pipe \u001b[39m=\u001b[39m Zero123Pipeline\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m     97\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcfg\u001b[39m.\u001b[39;49mpretrained_model_name_or_path,\n\u001b[1;32m     98\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpipe_kwargs,\n\u001b[0;32m---> 99\u001b[0m )\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_pipe(pipe)\n\u001b[1;32m    102\u001b[0m \u001b[39m# phi network for VSD\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39m# introduce two trainable modules:\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39m# - self.camera_embedding\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39m# - self.lora_layers\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/diffusers/pipelines/pipeline_utils.py:727\u001b[0m, in \u001b[0;36mDiffusionPipeline.to\u001b[0;34m(self, torch_device, torch_dtype, silence_dtype_warnings)\u001b[0m\n\u001b[1;32m    723\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    724\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe module \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodule\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been loaded in 8bit and moving it to \u001b[39m\u001b[39m{\u001b[39;00mtorch_dtype\u001b[39m}\u001b[39;00m\u001b[39m via `.to()` is not yet supported. Module is still on \u001b[39m\u001b[39m{\u001b[39;00mmodule\u001b[39m.\u001b[39mdevice\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    725\u001b[0m     )\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     module\u001b[39m.\u001b[39;49mto(torch_device, torch_dtype)\n\u001b[1;32m    729\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    730\u001b[0m     module\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mfloat16\n\u001b[1;32m    731\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mstr\u001b[39m(torch_device) \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    732\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m silence_dtype_warnings\n\u001b[1;32m    733\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_offloaded\n\u001b[1;32m    734\u001b[0m ):\n\u001b[1;32m    735\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    736\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` device. It\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    737\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m is not recommended to move them to `cpu` as running them will fail. Please make\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m `torch_dtype=torch.float16` argument, or use another device for inference.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    741\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 797 (7 times)]\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 47.54 GiB total capacity; 7.36 GiB already allocated; 11.12 MiB free; 7.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "%run launch.py --config configs/magic123-coarse-sd.yaml --train --gpu 0 \\\n",
    "data.image_path=\"{image_path}\" system.prompt_processor.prompt=\"{prompt}\" \\\n",
    "tag=Phase1 data.default_azimuth_deg={default_azimuth_deg} data.default_elevation_deg={default_elevation_deg} \\\n",
    "system.loss.lambda_depth=0.05 system.loss.lambda_depth_rel=\"[0, 0, 0.05, 100]\" system.loss.lambda_normal=\"[0, 0, 0.05, 100]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero123 + Stable Diffusion, ~10GB VRAM\n",
    "# data.image_path must point to a 4-channel RGBA image\n",
    "# system.prompt_proessor.prompt must be specified\n",
    "%run  launch.py --config configs/magic123-refine-sd.yaml --train --gpu 0 data.image_path=\"{image_path}\" system.prompt_processor.prompt=\"{prompt}\" system.geometry_convert_from=\"outputs/{workspace}/Phase1/ckpts/last.ckpt\" tag=Phase2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you're unsatisfied with the surface extracted using the default threshold (25)\n",
    "# you can specify a threshold value using `system.geometry_convert_override`\n",
    "# decrease the value if the extracted surface is incomplete, increase if it is extruded\n",
    "%run launch.py --config configs/magic123-refine-sd.yaml --train --gpu 0 data.image_path={image_path} system.prompt_processor.prompt={prompt} system.geometry_convert_from=\"outputs/{workspace}/Phase2/ckpts/last.ckpt\"  system.geometry_convert_override.isosurface_threshold=10."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "three",
   "language": "python",
   "name": "three"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
