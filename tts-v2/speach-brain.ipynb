{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --force-reinstall   torch torchvision  torchaudio --extra-index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /notebooks/\n",
    "!git clone https://github.com/huggingface/transformers.git\n",
    "%cd transformers\n",
    "!git pull\n",
    "%pip install -e .\n",
    "%cd /notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/speechbrain/speechbrain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install  librosa  --upgrade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests moviepy librosa pytube pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/espnet/espnet\n",
    "%pip install -q espnet_model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "def download_video_at_url(url,output_path):\n",
    "    # Utilisez la commande ! pour télécharger le fichier en utilisant aria2c\n",
    "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -o {output_path} {url}\n",
    "def split_audio_into_chunks(file_path, output_dir,minutes=5):\n",
    "    \"\"\"\n",
    "    Splits an audio file into five-minute chunks and saves them to the output directory.\n",
    "    \n",
    "    :param file_path: The path to the input audio file.\n",
    "    :param output_dir: The directory where the audio chunks will be saved.\n",
    "    \"\"\"\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    \n",
    "    # Define the length of each chunk in milliseconds (5 minutes)\n",
    "    chunk_length_ms = minutes * 60 * 1000\n",
    "    \n",
    "    # Split the audio into chunks\n",
    "    chunks = []\n",
    "    for i in range(0, len(audio), chunk_length_ms):\n",
    "        chunk = audio[i:i + chunk_length_ms]\n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    # Export each chunk as a separate audio file\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_filename = f\"{output_dir}/chunk_{i}.wav\"  # You can change the format to '.mp3' if needed\n",
    "        chunk.export(chunk_filename, format=\"wav\")  # Change 'wav' to 'mp3' if exporting as MP3\n",
    "        print(f\"Exported {chunk_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "# Function to download YouTube video\n",
    "def download_youtube_video(youtube_url, output_path):\n",
    "    !/root/miniconda3/envs/tts/bin/yt-dlp  -o {output_path} {youtube_url}\n",
    "    return output_path\n",
    "\n",
    "# Function to extract audio from video\n",
    "def extract_audio_from_video(video_path, audio_output_path):\n",
    "    with VideoFileClip(video_path) as video:\n",
    "        audio = video.audio\n",
    "        audio.write_audiofile(audio_output_path, codec='aac')\n",
    "\n",
    "# Function to resample audio\n",
    "def resample_audio(input_audio_path, output_audio_path, target_sr):\n",
    "    signal, sr_orig = librosa.load(input_audio_path, sr=None)  # Load audio without resampling\n",
    "    signal_resampled = librosa.resample(signal, orig_sr=sr_orig, target_sr=target_sr)  # Resample audio\n",
    "    sf.write(output_audio_path, signal_resampled, target_sr)  # Save resampled audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "from moviepy.editor import VideoFileClip\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "\n",
    "# URL of the YouTube video\n",
    "youtube_url = 'https://www.youtube.com/watch?v='\n",
    "\n",
    "# Paths for the downloaded video and audio files\n",
    "video_path = 'downloaded_video.mp4'\n",
    "audio_path = 'extracted_audio.aac'\n",
    "resampled_audio_path = 'resampled_audio.wav'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!rm /notebooks/{video_path}\n",
    "# Download the video from YouTube\n",
    "download_youtube_video(youtube_url, video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target sampling rate\n",
    "target_sampling_rate = 24000\n",
    "\n",
    "# Extract audio from the downloaded video\n",
    "extract_audio_from_video(video_path, audio_path)\n",
    "\n",
    "# Resample the extracted audio to the target sampling rate\n",
    "resample_audio(audio_path, resampled_audio_path, target_sampling_rate)\n",
    "\n",
    "print(f\"Resampled audio saved to: {resampled_audio_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyannote.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./reseampled_audio\n",
    "split_audio_into_chunks('resampled_audio.wav', './reseampled_audio',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='',add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Load your audio file (replace 'your_audio_file.wav' with your file path)\n",
    "y, sr = librosa.load('resampled_audio.wav', sr=None)  # 'sr=None' loads the file in its original sampling rate\n",
    "\n",
    "# Resample the audio to 48000 Hz\n",
    "y_48000 = librosa.resample(y,orig_sr=sr,target_sr=48000)\n",
    "\n",
    "# Save the resampled audio (replace 'resampled_audio.wav' with your desired output file path)\n",
    "sf.write('resampled_audio48.wav', y_48000, 48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from df.enhance import enhance, init_df, load_audio, save_audio\n",
    "from df.utils import download_file\n",
    "\n",
    "# Load default model\n",
    "model, df_state, _ = init_df()\n",
    "# Download and open some audio file. You use your audio files here\n",
    "audio_path = 'resampled_audio48.wav'\n",
    "audio, _ = load_audio(audio_path, sr=df_state.sr())\n",
    "# Denoise the audio\n",
    "enhanced = enhance(model, df_state, audio)\n",
    "# Save for listening\n",
    "save_audio(\"enhanced.wav\", enhanced, df_state.sr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Pipeline, Audio\n",
    "from pydub import AudioSegment\n",
    "import torch\n",
    "import os\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\")\n",
    "pipeline.to(torch.device(\"cuda\"))\n",
    "audio_path=\"enhanced.wav\"\n",
    "# apply pretrained pipeline\n",
    "diarization = pipeline(audio_path)\n",
    "audio = AudioSegment.from_wav(audio_path)\n",
    "output_dir = \"by_speaker\"\n",
    "!rm -rf {output_dir}\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "speakers = {}\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    start_ms = int(turn.start * 1000)\n",
    "    end_ms = int(turn.end * 1000)\n",
    "    \n",
    "    speaker_audio = audio[start_ms:end_ms]\n",
    "    if speaker not in speakers:\n",
    "        speakers[speaker] = speaker_audio\n",
    "    else:\n",
    "        speakers[speaker] += speaker_audio\n",
    "\n",
    "for speaker, audio in speakers.items():\n",
    "    audio.export(os.path.join(output_dir, f\"{speaker}.wav\"), format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./reseampled_audio\n",
    "split_audio_into_chunks('/notebooks/by_speaker/SPEAKER_01.wav', './reseampled_audio',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Load audio file\n",
    "audio = AudioSegment.from_wav(\"/notebooks/by_speaker/SPEAKER_01.wav\") \n",
    "\n",
    "# Get start and end times in milliseconds\n",
    "start_time = 0.05*60*1000 + 0*1000 # 2 min 54 sec\n",
    "end_time = 0.15*60*1000 + 0*1000  # 4 min\n",
    "\n",
    "# Extract segment\n",
    "segment = audio[start_time:end_time]\n",
    "\n",
    "# Resample to 24000 Hz\n",
    "segment = segment.set_frame_rate(16000)\n",
    "\n",
    "# Convert to mono\n",
    "segment = segment.set_channels(1)\n",
    "\n",
    "# Export to wav file\n",
    "segment.export(\"segment_24kmono.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from espnet_model_zoo.downloader import ModelDownloader\n",
    "\n",
    "d = ModelDownloader()\n",
    "cfg = d.download_and_unpack(\"espnet/Wangyou_Zhang_chime4_enh_train_enh_conv_tasnet_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import soundfile\n",
    "from IPython.display import display, Audio\n",
    "mixwav_mc, sr = soundfile.read(\"/notebooks/by_speaker/SPEAKER_00.wav\")\n",
    "# mixwav.shape: num_samples, num_channels\n",
    "mixwav_sc = mixwav_mc[:]\n",
    "display(Audio(mixwav_mc.T, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import soundfile\n",
    "from espnet2.bin.enh_inference import SeparateSpeech\n",
    "\n",
    "\n",
    "separate_speech = {}\n",
    "# For models downloaded from GoogleDrive, you can use the following script:\n",
    "enh_model_sc = SeparateSpeech(\n",
    "  train_config=cfg[\"train_config\"],\n",
    "  model_file=cfg[\"model_file\"],\n",
    "  # for segment-wise process on long speech\n",
    "  normalize_segment_scale=True,\n",
    "  show_progressbar=True,\n",
    "  ref_channel=1,\n",
    "  normalize_output_wav=True,\n",
    "  device=\"cuda:0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# play the enhanced single-channel speech\n",
    "wave = enh_model_sc(mixwav_sc[None, ...], sr)\n",
    "print(\"Input real noisy speech\", flush=True)\n",
    "display(Audio(mixwav_sc, rate=sr))\n",
    "print(\"Enhanced speech\", flush=True)\n",
    "display(Audio(wave[0].squeeze(), rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundfile.write(\"enhanced.wav\", wave[0].squeeze(), sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "Audio('enhanced.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio('/notebooks/by_speaker/SPEAKER_00.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio('enhanced.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts",
   "language": "python",
   "name": "tts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
