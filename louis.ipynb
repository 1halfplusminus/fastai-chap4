{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt install peg\n",
    "%pip install spleeter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xformers==0.0.19 torch==2.0.0+cu118 torchvision  torchaudio --extra-index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pytube moviepy spleeter\n",
    "%pip uninstall ffmpeg-python -y\n",
    "%pip install ffmpeg-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install speechbrain soundfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pydub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir  /notebooks/motivation\n",
    "%cd /notebooks/motivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "\n",
    "# specify the URL of the video\n",
    "url = 'https://www.youtube.com/watch?v=GEyn-nzqiNo'\n",
    "yt = YouTube(url)\n",
    "\n",
    "# download the highest resolution version of the video\n",
    "ys = yt.streams.get_highest_resolution()\n",
    "ys.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/espnet/espnet\n",
    "%pip install -q espnet_model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email.mime import audio\n",
    "from moviepy.editor import *\n",
    "import os\n",
    "\n",
    "\n",
    "def extract_audio(video_path, audio_output_path):\n",
    "    video = VideoFileClip(video_path)\n",
    "    audio = video.audio\n",
    "    audio.write_audiofile(audio_output_path)\n",
    "    \n",
    "videos_directory = '/notebooks/motivation'\n",
    "audio_files_directory = './audio'\n",
    "audio_enhanced_directory = './audio_enhanced'\n",
    "audio_separated_directory = './audio_separated'\n",
    "audio_separated_vocals_directory = './audio_separated_vocals'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {videos_directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(audio_enhanced_directory):\n",
    "    os.makedirs(audio_enhanced_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(audio_files_directory):\n",
    "    os.makedirs(audio_files_directory)\n",
    "\n",
    "for video_file in os.listdir(videos_directory):\n",
    "    if video_file.endswith(\".mp4\"):\n",
    "        video_path = os.path.join(videos_directory, video_file)\n",
    "        audio_output_path = os.path.join(audio_files_directory, f'{video_file[:-4]}.wav')\n",
    "        extract_audio(video_path, audio_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "import os\n",
    "def split_audio(file_path, output_dir):\n",
    "    audio = mp.AudioFileClip(file_path)\n",
    "    duration = audio.duration\n",
    "    intervals = int(duration // 300) + (1 if duration % 300 > 0 else 0)\n",
    "    for i in range(intervals):\n",
    "        start_time = i * 300\n",
    "        end_time = (i + 1) * 300 if (i + 1) * 300 < duration else duration\n",
    "        chunk = audio.subclip(start_time, end_time)\n",
    "        chunk_filename = os.path.join(output_dir, f\"{i}_{os.path.basename(file_path)}\")\n",
    "        chunk.write_audiofile(chunk_filename)\n",
    "    audio.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = audio_files_directory\n",
    "audio_files = [f for f in os.listdir(input_dir) if f.endswith(('.mp3', '.wav'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./audio_chunks\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for audio_file in audio_files:\n",
    "    file_path = os.path.join(input_dir, audio_file)\n",
    "    split_audio(file_path, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import soundfile as sf\n",
    "\n",
    "input_dir = \"./audio_chunks\"\n",
    "output_dir = \"./audio_enhanced_chunks\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "audio_files = [f for f in os.listdir(input_dir) if f.endswith(('.mp3', '.wav'))]\n",
    "for audio_file in audio_files:\n",
    "    file_path = os.path.join(input_dir, audio_file)\n",
    "\n",
    "    # Load audio file using pydub\n",
    "    mixwav_mc, sr = soundfile.read(file_path)\n",
    "    mixwav_sc = mixwav_mc[:,1]\n",
    "    wave = enh_model_sc(mixwav_sc[None, ...], sr)\n",
    "\n",
    "    # Create a new filename for the enhanced audio\n",
    "    enhanced_filename = f\"enhanced_{audio_file}\"\n",
    "    enhanced_filepath = os.path.join(output_dir, enhanced_filename)\n",
    "\n",
    "    # Save the enhanced audio to the output_dir\n",
    "    sf.write(enhanced_filepath, wave[0].squeeze(), sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "output_dir = \"./audio_enhanced_chunks\"\n",
    "combined_output_file = \"./combined_enhanced_audio.wav\"\n",
    "\n",
    "# Get a list of all the enhanced audio files\n",
    "enhanced_audio_files = [f for f in os.listdir(output_dir) if f.endswith(('.wav', '.mp3'))]\n",
    "\n",
    "# Initialize an empty audio segment\n",
    "combined_segment = AudioSegment.empty()\n",
    "\n",
    "# Iterate through each enhanced audio file, loading and concatenating them\n",
    "for enhanced_audio_file in enhanced_audio_files:\n",
    "    enhanced_filepath = os.path.join(output_dir, enhanced_audio_file)\n",
    "    enhanced_segment = AudioSegment.from_wav(enhanced_filepath) if enhanced_audio_file.endswith('.wav') else AudioSegment.from_mp3(enhanced_filepath)\n",
    "    combined_segment += enhanced_segment\n",
    "\n",
    "# Export the combined audio segment to a new file\n",
    "combined_segment.export(combined_output_file, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyannote.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "audio_file=\"/notebooks/tamioc2/audio/vocals/vocal_Tamioc, le nouveau podcast du Pacifique.wav_10.wav\"\n",
    "if not os.path.exists(audio_file):\n",
    "    os.makedirs(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.0\",\n",
    "                                    use_auth_token=\"\")\n",
    "\n",
    "pipeline.to(torch.device(\"cuda\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from pyannote.audio.pipelines.utils.hook import ProgressHook\n",
    "with ProgressHook() as hook:\n",
    "    waveform, sample_rate = torchaudio.load(audio_file)\n",
    "    diarization = pipeline({\"waveform\": waveform, \"sample_rate\": sample_rate}, hook=hook)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.core import Segment\n",
    "from pyannote.audio import Audio\n",
    "from pydub import AudioSegment\n",
    "\n",
    "output_dir = \"./by_speaker\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "# Load the audio file\n",
    "audio = AudioSegment.from_wav(audio_file)\n",
    "\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    # Get the start and end times (in milliseconds) of the speaker segment\n",
    "    start_time_ms = int(turn.start * 1000)\n",
    "    end_time_ms = int(turn.end * 1000)\n",
    "\n",
    "    # Extract the speaker segment from the audio file\n",
    "    speaker_segment = audio[start_time_ms:end_time_ms]\n",
    "\n",
    "    # Build the output filename\n",
    "    speaker_label = f'speaker_{speaker}_'\n",
    "    segment_label = f'{turn.start:.3f}-{turn.end:.3f}'.replace('.', '_')\n",
    "    filename = f'{speaker_label}{segment_label}.wav'\n",
    "\n",
    "    # Save the speaker segment to disk\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    speaker_segment.export(output_path, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "output_dir = \"./by_speaker\"\n",
    "source_directory = output_dir # replace with the path to your directory\n",
    "files = [f for f in os.listdir(source_directory) if os.path.isfile(os.path.join(source_directory, f))]\n",
    "for file in files:\n",
    "    # Extract the speaker's name from the filename\n",
    "    speaker_name = file.split('_')[2]\n",
    "    \n",
    "    # Create a new directory for the speaker if it doesn't already exist\n",
    "    speaker_directory = os.path.join(source_directory, speaker_name)\n",
    "    if not os.path.exists(speaker_directory):\n",
    "        os.makedirs(speaker_directory)\n",
    "    \n",
    "    # Move the file into the speaker's directory\n",
    "    source_file_path = os.path.join(source_directory, file)\n",
    "    destination_file_path = os.path.join(speaker_directory, file)\n",
    "    shutil.move(source_file_path, destination_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./by_speaker\"\n",
    "input_dir = output_dir\n",
    "output_dir = \"tamioc_merged_by_speaker\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for speaker in set(speaker for filename in os.listdir(input_dir) for speaker in [filename.split('_')[2]]):\n",
    "    # Initialize an empty audio segment\n",
    "    merged_clip = AudioSegment.empty()\n",
    "    # List to hold clips temporarily\n",
    "    temp_clips = []\n",
    "    # Counter for naming output files\n",
    "    counter = 0\n",
    "\n",
    "    # Get a list of all clips for this speaker\n",
    "    speaker_clips = [filename for filename in os.listdir(input_dir) if filename.startswith(\"speaker_SPEAKER_\"+speaker) and os.path.isfile(os.path.join(input_dir, filename))]\n",
    "    \n",
    "    for filename in speaker_clips:\n",
    "        # Load the clip\n",
    "        clip = AudioSegment.from_wav(os.path.join(input_dir, filename))\n",
    "        temp_clips.append(clip)\n",
    "        # Check the total duration of clips in temp_clips\n",
    "        total_duration_ms = sum(temp_clip.duration_seconds for temp_clip in temp_clips) * 1000\n",
    "        \n",
    "        # If total duration reaches 5 minutes, merge and save the clips\n",
    "        if total_duration_ms >= 300000:\n",
    "            merged_clip = sum(temp_clips, AudioSegment.empty())\n",
    "            output_filename = f\"{speaker}_{counter:03d}.wav\"\n",
    "            merged_clip.export(os.path.join(output_dir, output_filename), format=\"wav\")\n",
    "            # Reset temp_clips and increment counter\n",
    "            temp_clips = []\n",
    "            counter += 1\n",
    "\n",
    "    # Merge and save any remaining clips\n",
    "    if temp_clips:\n",
    "        merged_clip = sum(temp_clips, AudioSegment.empty())\n",
    "        output_filename = f\"{speaker}_{counter:03d}.wav\"\n",
    "        merged_clip.export(os.path.join(output_dir, output_filename), format=\"wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
