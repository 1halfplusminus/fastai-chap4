{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fastbook transformers tokenizers==0.12.0 torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import fastbook\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "import numpy as np\n",
    "import numpy.random as nprnd\n",
    "\n",
    "fastbook.setup_book()\n",
    "model_name = \"microsoft/deberta-v3-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,Dataset\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "from datasets import load_dataset\n",
    "\n",
    "def concat_columns(example):\n",
    "    example['input'] = 'TEXT1: ' + example[\"context\"] + '; TEXT2: ' + example[\"target\"] + '; ANC1: ' + example[\"anchor\"]\n",
    "    return example\n",
    "\n",
    "def process_dataset(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"input\"] = 'TEXT1: ' + df[\"context\"] + '; TEXT2: ' + df[\"target\"] + '; ANC1: ' + df[\"anchor\"]\n",
    "    train_dataset = Dataset.from_pandas(df)\n",
    "    return train_dataset\n",
    "test_dataset = process_dataset('./test.csv')\n",
    "train_dataset = process_dataset('./train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(examples):\n",
    "    return tokenizer(examples['input'])\n",
    "\n",
    "train_dataset = train_dataset.map(encode, batched=True)\n",
    "test_dataset = test_dataset.map(encode, batched=True)\n",
    "print(test_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.rename_columns({'score':'labels'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(x,y): return np.corrcoef(x,y)[0][1]\n",
    "def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
    "lr = 8e-5\n",
    "bs = 128\n",
    "epochs = 4\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
    "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
    "    num_train_epochs=epochs, weight_decay=0.01, report_to='none')\n",
    "\n",
    "# Create the Trainer and train the model\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset,          # evaluation dataset,\n",
    "    tokenizer=tokenizer, \n",
    "    compute_metrics=corr_d\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "preds = trainer.predict(test_dataset).predictions.astype(float)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.clip(preds, 0, 1)\n",
    "preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
